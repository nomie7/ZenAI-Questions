module.exports = [
"[project]/node_modules/@graphql-tools/schema/cjs/assertResolversPresent.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.assertResolversPresent = assertResolversPresent;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
function assertResolversPresent(schema, resolverValidationOptions = {}) {
    const { requireResolversForArgs, requireResolversForNonScalar, requireResolversForAllFields } = resolverValidationOptions;
    if (requireResolversForAllFields && (requireResolversForArgs || requireResolversForNonScalar)) {
        throw new TypeError('requireResolversForAllFields takes precedence over the more specific assertions. ' + 'Please configure either requireResolversForAllFields or requireResolversForArgs / ' + 'requireResolversForNonScalar, but not a combination of them.');
    }
    (0, utils_1.forEachField)(schema, (field, typeName, fieldName)=>{
        // requires a resolver for *every* field.
        if (requireResolversForAllFields) {
            expectResolver('requireResolversForAllFields', requireResolversForAllFields, field, typeName, fieldName);
        }
        // requires a resolver on every field that has arguments
        if (requireResolversForArgs && field.args.length > 0) {
            expectResolver('requireResolversForArgs', requireResolversForArgs, field, typeName, fieldName);
        }
        // requires a resolver on every field that returns a non-scalar type
        if (requireResolversForNonScalar !== 'ignore' && !(0, graphql_1.isScalarType)((0, graphql_1.getNamedType)(field.type))) {
            expectResolver('requireResolversForNonScalar', requireResolversForNonScalar, field, typeName, fieldName);
        }
    });
}
function expectResolver(validator, behavior, field, typeName, fieldName) {
    if (!field.resolve) {
        const message = `Resolver missing for "${typeName}.${fieldName}".
To disable this validator, use:
  resolverValidationOptions: {
    ${validator}: 'ignore'
  }`;
        if (behavior === 'error') {
            throw new Error(message);
        }
        if (behavior === 'warn') {
            console.warn(message);
        }
        return;
    }
    if (typeof field.resolve !== 'function') {
        throw new Error(`Resolver "${typeName}.${fieldName}" must be a function`);
    }
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/chainResolvers.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.chainResolvers = chainResolvers;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
function chainResolvers(resolvers) {
    return (root, args, ctx, info)=>resolvers.reduce((prev, curResolver)=>{
            if (curResolver != null) {
                return curResolver(prev, args, ctx, info);
            }
            return (0, graphql_1.defaultFieldResolver)(prev, args, ctx, info);
        }, root);
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/checkForResolveTypeResolver.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.checkForResolveTypeResolver = checkForResolveTypeResolver;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
// If we have any union or interface types throw if no there is no resolveType resolver
function checkForResolveTypeResolver(schema, requireResolversForResolveType) {
    (0, utils_1.mapSchema)(schema, {
        [utils_1.MapperKind.ABSTRACT_TYPE]: (type)=>{
            if (!type.resolveType) {
                const message = `Type "${type.name}" is missing a "__resolveType" resolver. Pass 'ignore' into ` + '"resolverValidationOptions.requireResolversForResolveType" to disable this error.';
                if (requireResolversForResolveType === 'error') {
                    throw new Error(message);
                }
                if (requireResolversForResolveType === 'warn') {
                    console.warn(message);
                }
            }
            return undefined;
        }
    });
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/extendResolversFromInterfaces.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.extendResolversFromInterfaces = extendResolversFromInterfaces;
function extendResolversFromInterfaces(schema, resolvers) {
    const extendedResolvers = {};
    const typeMap = schema.getTypeMap();
    for(const typeName in typeMap){
        const type = typeMap[typeName];
        if ('getInterfaces' in type) {
            extendedResolvers[typeName] = {};
            for (const iFace of type.getInterfaces()){
                if (resolvers[iFace.name]) {
                    for(const fieldName in resolvers[iFace.name]){
                        if (fieldName === '__isTypeOf' || !fieldName.startsWith('__')) {
                            extendedResolvers[typeName][fieldName] = resolvers[iFace.name][fieldName];
                        }
                    }
                }
            }
            const typeResolvers = resolvers[typeName];
            extendedResolvers[typeName] = {
                ...extendedResolvers[typeName],
                ...typeResolvers
            };
        } else {
            const typeResolvers = resolvers[typeName];
            if (typeResolvers != null) {
                extendedResolvers[typeName] = typeResolvers;
            }
        }
    }
    return extendedResolvers;
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/addResolversToSchema.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.addResolversToSchema = addResolversToSchema;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const checkForResolveTypeResolver_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/checkForResolveTypeResolver.js [app-route] (ecmascript)");
const extendResolversFromInterfaces_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/extendResolversFromInterfaces.js [app-route] (ecmascript)");
function addResolversToSchema({ schema, resolvers: inputResolvers, defaultFieldResolver, resolverValidationOptions = {}, inheritResolversFromInterfaces = false, updateResolversInPlace = false }) {
    const { requireResolversToMatchSchema = 'error', requireResolversForResolveType } = resolverValidationOptions;
    const resolvers = inheritResolversFromInterfaces ? (0, extendResolversFromInterfaces_js_1.extendResolversFromInterfaces)(schema, inputResolvers) : inputResolvers;
    for(const typeName in resolvers){
        const resolverValue = resolvers[typeName];
        const resolverType = typeof resolverValue;
        if (resolverType !== 'object') {
            throw new Error(`"${typeName}" defined in resolvers, but has invalid value "${resolverValue}". The resolver's value must be of type object.`);
        }
        const type = schema.getType(typeName);
        if (type == null) {
            const msg = `"${typeName}" defined in resolvers, but not in schema`;
            if (requireResolversToMatchSchema && requireResolversToMatchSchema !== 'error') {
                if (requireResolversToMatchSchema === 'warn') {
                    console.warn(msg);
                }
                continue;
            }
            throw new Error(msg);
        } else if ((0, graphql_1.isSpecifiedScalarType)(type)) {
            // allow -- without recommending -- overriding of specified scalar types
            for(const fieldName in resolverValue){
                if (fieldName.startsWith('__')) {
                    type[fieldName.substring(2)] = resolverValue[fieldName];
                } else {
                    type[fieldName] = resolverValue[fieldName];
                }
            }
        } else if ((0, graphql_1.isEnumType)(type)) {
            const values = type.getValues();
            for(const fieldName in resolverValue){
                if (!fieldName.startsWith('__') && !values.some((value)=>value.name === fieldName) && requireResolversToMatchSchema && requireResolversToMatchSchema !== 'ignore') {
                    const msg = `${type.name}.${fieldName} was defined in resolvers, but not present within ${type.name}`;
                    if (requireResolversToMatchSchema === 'error') {
                        throw new Error(msg);
                    } else {
                        console.warn(msg);
                    }
                }
            }
        } else if ((0, graphql_1.isUnionType)(type)) {
            for(const fieldName in resolverValue){
                if (!fieldName.startsWith('__') && requireResolversToMatchSchema && requireResolversToMatchSchema !== 'ignore') {
                    const msg = `${type.name}.${fieldName} was defined in resolvers, but ${type.name} is not an object or interface type`;
                    if (requireResolversToMatchSchema === 'error') {
                        throw new Error(msg);
                    } else {
                        console.warn(msg);
                    }
                }
            }
        } else if ((0, graphql_1.isObjectType)(type) || (0, graphql_1.isInterfaceType)(type)) {
            for(const fieldName in resolverValue){
                if (!fieldName.startsWith('__')) {
                    const fields = type.getFields();
                    const field = fields[fieldName];
                    if (field == null) {
                        // Field present in resolver but not in schema
                        if (requireResolversToMatchSchema && requireResolversToMatchSchema !== 'ignore') {
                            const msg = `${typeName}.${fieldName} defined in resolvers, but not in schema`;
                            if (requireResolversToMatchSchema === 'error') {
                                throw new Error(msg);
                            } else {
                                console.error(msg);
                            }
                        }
                    } else {
                        // Field present in both the resolver and schema
                        const fieldResolve = resolverValue[fieldName];
                        if (typeof fieldResolve !== 'function' && typeof fieldResolve !== 'object') {
                            throw new Error(`Resolver ${typeName}.${fieldName} must be object or function`);
                        }
                    }
                }
            }
        }
    }
    schema = updateResolversInPlace ? addResolversToExistingSchema(schema, resolvers, defaultFieldResolver) : createNewSchemaWithResolvers(schema, resolvers, defaultFieldResolver);
    if (requireResolversForResolveType && requireResolversForResolveType !== 'ignore') {
        (0, checkForResolveTypeResolver_js_1.checkForResolveTypeResolver)(schema, requireResolversForResolveType);
    }
    return schema;
}
function addResolversToExistingSchema(schema, resolvers, defaultFieldResolver) {
    const typeMap = schema.getTypeMap();
    for(const typeName in resolvers){
        const type = schema.getType(typeName);
        const resolverValue = resolvers[typeName];
        if ((0, graphql_1.isScalarType)(type)) {
            for(const fieldName in resolverValue){
                if (fieldName.startsWith('__')) {
                    type[fieldName.substring(2)] = resolverValue[fieldName];
                } else if (fieldName === 'astNode' && type.astNode != null) {
                    type.astNode = {
                        ...type.astNode,
                        description: resolverValue?.astNode?.description ?? type.astNode.description,
                        directives: (type.astNode.directives ?? []).concat(resolverValue?.astNode?.directives ?? [])
                    };
                } else if (fieldName === 'extensionASTNodes' && type.extensionASTNodes != null) {
                    type.extensionASTNodes = type.extensionASTNodes.concat(resolverValue?.extensionASTNodes ?? []);
                } else if (fieldName === 'extensions' && type.extensions != null && resolverValue.extensions != null) {
                    type.extensions = Object.assign(Object.create(null), type.extensions, resolverValue.extensions);
                } else {
                    type[fieldName] = resolverValue[fieldName];
                }
            }
        } else if ((0, graphql_1.isEnumType)(type)) {
            const config = type.toConfig();
            const enumValueConfigMap = config.values;
            for(const fieldName in resolverValue){
                if (fieldName.startsWith('__')) {
                    config[fieldName.substring(2)] = resolverValue[fieldName];
                } else if (fieldName === 'astNode' && config.astNode != null) {
                    config.astNode = {
                        ...config.astNode,
                        description: resolverValue?.astNode?.description ?? config.astNode.description,
                        directives: (config.astNode.directives ?? []).concat(resolverValue?.astNode?.directives ?? [])
                    };
                } else if (fieldName === 'extensionASTNodes' && config.extensionASTNodes != null) {
                    config.extensionASTNodes = config.extensionASTNodes.concat(resolverValue?.extensionASTNodes ?? []);
                } else if (fieldName === 'extensions' && type.extensions != null && resolverValue.extensions != null) {
                    type.extensions = Object.assign(Object.create(null), type.extensions, resolverValue.extensions);
                } else if (enumValueConfigMap[fieldName]) {
                    enumValueConfigMap[fieldName].value = resolverValue[fieldName];
                }
            }
            typeMap[typeName] = new graphql_1.GraphQLEnumType(config);
        } else if ((0, graphql_1.isUnionType)(type)) {
            for(const fieldName in resolverValue){
                if (fieldName.startsWith('__')) {
                    type[fieldName.substring(2)] = resolverValue[fieldName];
                }
            }
        } else if ((0, graphql_1.isObjectType)(type) || (0, graphql_1.isInterfaceType)(type)) {
            for(const fieldName in resolverValue){
                if (fieldName.startsWith('__')) {
                    // this is for isTypeOf and resolveType and all the other stuff.
                    type[fieldName.substring(2)] = resolverValue[fieldName];
                    continue;
                }
                const fields = type.getFields();
                const field = fields[fieldName];
                if (field != null) {
                    const fieldResolve = resolverValue[fieldName];
                    if (typeof fieldResolve === 'function') {
                        // for convenience. Allows shorter syntax in resolver definition file
                        field.resolve = fieldResolve.bind(resolverValue);
                    } else {
                        setFieldProperties(field, fieldResolve);
                    }
                }
            }
        }
    }
    // serialize all default values prior to healing fields with new scalar/enum types.
    (0, utils_1.forEachDefaultValue)(schema, utils_1.serializeInputValue);
    // schema may have new scalar/enum types that require healing
    (0, utils_1.healSchema)(schema);
    // reparse all default values with new parsing functions.
    (0, utils_1.forEachDefaultValue)(schema, utils_1.parseInputValue);
    if (defaultFieldResolver != null) {
        (0, utils_1.forEachField)(schema, (field)=>{
            if (!field.resolve) {
                field.resolve = defaultFieldResolver;
            }
        });
    }
    return schema;
}
function createNewSchemaWithResolvers(schema, resolvers, defaultFieldResolver) {
    schema = (0, utils_1.mapSchema)(schema, {
        [utils_1.MapperKind.SCALAR_TYPE]: (type)=>{
            const config = type.toConfig();
            const resolverValue = resolvers[type.name];
            if (!(0, graphql_1.isSpecifiedScalarType)(type) && resolverValue != null) {
                for(const fieldName in resolverValue){
                    if (fieldName.startsWith('__')) {
                        config[fieldName.substring(2)] = resolverValue[fieldName];
                    } else if (fieldName === 'astNode' && config.astNode != null) {
                        config.astNode = {
                            ...config.astNode,
                            description: resolverValue?.astNode?.description ?? config.astNode.description,
                            directives: (config.astNode.directives ?? []).concat(resolverValue?.astNode?.directives ?? [])
                        };
                    } else if (fieldName === 'extensionASTNodes' && config.extensionASTNodes != null) {
                        config.extensionASTNodes = config.extensionASTNodes.concat(resolverValue?.extensionASTNodes ?? []);
                    } else if (fieldName === 'extensions' && config.extensions != null && resolverValue.extensions != null) {
                        config.extensions = Object.assign(Object.create(null), type.extensions, resolverValue.extensions);
                    } else {
                        config[fieldName] = resolverValue[fieldName];
                    }
                }
                return new graphql_1.GraphQLScalarType(config);
            }
        },
        [utils_1.MapperKind.ENUM_TYPE]: (type)=>{
            const resolverValue = resolvers[type.name];
            const config = type.toConfig();
            const enumValueConfigMap = config.values;
            if (resolverValue != null) {
                for(const fieldName in resolverValue){
                    if (fieldName.startsWith('__')) {
                        config[fieldName.substring(2)] = resolverValue[fieldName];
                    } else if (fieldName === 'astNode' && config.astNode != null) {
                        config.astNode = {
                            ...config.astNode,
                            description: resolverValue?.astNode?.description ?? config.astNode.description,
                            directives: (config.astNode.directives ?? []).concat(resolverValue?.astNode?.directives ?? [])
                        };
                    } else if (fieldName === 'extensionASTNodes' && config.extensionASTNodes != null) {
                        config.extensionASTNodes = config.extensionASTNodes.concat(resolverValue?.extensionASTNodes ?? []);
                    } else if (fieldName === 'extensions' && config.extensions != null && resolverValue.extensions != null) {
                        config.extensions = Object.assign(Object.create(null), type.extensions, resolverValue.extensions);
                    } else if (enumValueConfigMap[fieldName]) {
                        enumValueConfigMap[fieldName].value = resolverValue[fieldName];
                    }
                }
                return new graphql_1.GraphQLEnumType(config);
            }
        },
        [utils_1.MapperKind.UNION_TYPE]: (type)=>{
            const resolverValue = resolvers[type.name];
            if (resolverValue != null) {
                const config = type.toConfig();
                if (resolverValue['__resolveType']) {
                    config.resolveType = resolverValue['__resolveType'];
                }
                return new graphql_1.GraphQLUnionType(config);
            }
        },
        [utils_1.MapperKind.OBJECT_TYPE]: (type)=>{
            const resolverValue = resolvers[type.name];
            if (resolverValue != null) {
                const config = type.toConfig();
                if (resolverValue['__isTypeOf']) {
                    config.isTypeOf = resolverValue['__isTypeOf'];
                }
                return new graphql_1.GraphQLObjectType(config);
            }
        },
        [utils_1.MapperKind.INTERFACE_TYPE]: (type)=>{
            const resolverValue = resolvers[type.name];
            if (resolverValue != null) {
                const config = type.toConfig();
                if (resolverValue['__resolveType']) {
                    config.resolveType = resolverValue['__resolveType'];
                }
                return new graphql_1.GraphQLInterfaceType(config);
            }
        },
        [utils_1.MapperKind.COMPOSITE_FIELD]: (fieldConfig, fieldName, typeName)=>{
            const resolverValue = resolvers[typeName];
            if (resolverValue != null) {
                const fieldResolve = resolverValue[fieldName];
                if (fieldResolve != null) {
                    const newFieldConfig = {
                        ...fieldConfig
                    };
                    if (typeof fieldResolve === 'function') {
                        // for convenience. Allows shorter syntax in resolver definition file
                        newFieldConfig.resolve = fieldResolve.bind(resolverValue);
                    } else {
                        setFieldProperties(newFieldConfig, fieldResolve);
                    }
                    return newFieldConfig;
                }
            }
        }
    });
    if (defaultFieldResolver != null) {
        schema = (0, utils_1.mapSchema)(schema, {
            [utils_1.MapperKind.OBJECT_FIELD]: (fieldConfig)=>({
                    ...fieldConfig,
                    resolve: fieldConfig.resolve != null ? fieldConfig.resolve : defaultFieldResolver
                })
        });
    }
    return schema;
}
function setFieldProperties(field, propertiesObj) {
    for(const propertyName in propertiesObj){
        field[propertyName] = propertiesObj[propertyName];
    }
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/makeExecutableSchema.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeExecutableSchema = makeExecutableSchema;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const merge_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/index.js [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const addResolversToSchema_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/addResolversToSchema.js [app-route] (ecmascript)");
const assertResolversPresent_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/assertResolversPresent.js [app-route] (ecmascript)");
/**
 * Builds a schema from the provided type definitions and resolvers.
 *
 * The type definitions are written using Schema Definition Language (SDL). They
 * can be provided as a string, a `DocumentNode`, a function, or an array of any
 * of these. If a function is provided, it will be passed no arguments and
 * should return an array of strings or `DocumentNode`s.
 *
 * Note: You can use GraphQL magic comment provide additional syntax
 * highlighting in your editor (with the appropriate editor plugin).
 *
 * ```js
 * const typeDefs = /* GraphQL *\/ `
 *   type Query {
 *     posts: [Post]
 *     author(id: Int!): Author
 *   }
 * `;
 * ```
 *
 * The `resolvers` object should be a map of type names to nested object, which
 * themselves map the type's fields to their appropriate resolvers.
 * See the [Resolvers](/docs/resolvers) section of the documentation for more details.
 *
 * ```js
 * const resolvers = {
 *   Query: {
 *     posts: (obj, args, ctx, info) => getAllPosts(),
 *     author: (obj, args, ctx, info) => getAuthorById(args.id)
 *   }
 * };
 * ```
 *
 * Once you've defined both the `typeDefs` and `resolvers`, you can create your
 * schema:
 *
 * ```js
 * const schema = makeExecutableSchema({
 *   typeDefs,
 *   resolvers,
 * })
 * ```
 */ function makeExecutableSchema({ typeDefs, resolvers = {}, resolverValidationOptions = {}, inheritResolversFromInterfaces = false, updateResolversInPlace = false, schemaExtensions, defaultFieldResolver, ...otherOptions }) {
    // Validate and clean up arguments
    if (typeof resolverValidationOptions !== 'object') {
        throw new Error('Expected `resolverValidationOptions` to be an object');
    }
    if (!typeDefs) {
        throw new Error('Must provide typeDefs');
    }
    let schema;
    if ((0, graphql_1.isSchema)(typeDefs)) {
        schema = typeDefs;
    } else if (otherOptions?.commentDescriptions) {
        const mergedTypeDefs = (0, merge_1.mergeTypeDefs)(typeDefs, {
            ...otherOptions,
            commentDescriptions: true
        });
        schema = (0, graphql_1.buildSchema)(mergedTypeDefs, otherOptions);
    } else {
        const mergedTypeDefs = (0, merge_1.mergeTypeDefs)(typeDefs, otherOptions);
        schema = (0, graphql_1.buildASTSchema)(mergedTypeDefs, otherOptions);
    }
    // We allow passing in an array of resolver maps, in which case we merge them
    schema = (0, addResolversToSchema_js_1.addResolversToSchema)({
        schema,
        resolvers: (0, merge_1.mergeResolvers)(resolvers),
        resolverValidationOptions,
        inheritResolversFromInterfaces,
        updateResolversInPlace,
        defaultFieldResolver
    });
    if (Object.keys(resolverValidationOptions).length > 0) {
        (0, assertResolversPresent_js_1.assertResolversPresent)(schema, resolverValidationOptions);
    }
    if (schemaExtensions) {
        for (const schemaExtension of (0, utils_1.asArray)(schemaExtensions)){
            (0, merge_1.applyExtensions)(schema, schemaExtension);
        }
    }
    return schema;
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/types.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {

}),
"[project]/node_modules/@graphql-tools/schema/cjs/merge-schemas.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeSchemas = mergeSchemas;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const makeExecutableSchema_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/makeExecutableSchema.js [app-route] (ecmascript)");
/**
 * Synchronously merges multiple schemas, typeDefinitions and/or resolvers into a single schema.
 * @param config Configuration object
 */ function mergeSchemas(config) {
    const extractedTypeDefs = [];
    const extractedResolvers = [];
    const extractedSchemaExtensions = [];
    if (config.schemas != null) {
        for (const schema of config.schemas){
            extractedTypeDefs.push((0, utils_1.getDocumentNodeFromSchema)(schema));
            extractedResolvers.push((0, utils_1.getResolversFromSchema)(schema));
            extractedSchemaExtensions.push((0, utils_1.extractExtensionsFromSchema)(schema));
        }
    }
    if (config.typeDefs != null) {
        extractedTypeDefs.push(config.typeDefs);
    }
    if (config.resolvers != null) {
        const additionalResolvers = (0, utils_1.asArray)(config.resolvers);
        extractedResolvers.push(...additionalResolvers);
    }
    if (config.schemaExtensions != null) {
        const additionalSchemaExtensions = (0, utils_1.asArray)(config.schemaExtensions);
        extractedSchemaExtensions.push(...additionalSchemaExtensions);
    }
    return (0, makeExecutableSchema_js_1.makeExecutableSchema)({
        ...config,
        typeDefs: extractedTypeDefs,
        resolvers: extractedResolvers,
        schemaExtensions: extractedSchemaExtensions
    });
}
}),
"[project]/node_modules/@graphql-tools/schema/cjs/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.extractExtensionsFromSchema = exports.extendResolversFromInterfaces = exports.checkForResolveTypeResolver = exports.addResolversToSchema = exports.chainResolvers = exports.assertResolversPresent = void 0;
const tslib_1 = __turbopack_context__.r("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
var assertResolversPresent_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/assertResolversPresent.js [app-route] (ecmascript)");
Object.defineProperty(exports, "assertResolversPresent", {
    enumerable: true,
    get: function() {
        return assertResolversPresent_js_1.assertResolversPresent;
    }
});
var chainResolvers_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/chainResolvers.js [app-route] (ecmascript)");
Object.defineProperty(exports, "chainResolvers", {
    enumerable: true,
    get: function() {
        return chainResolvers_js_1.chainResolvers;
    }
});
var addResolversToSchema_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/addResolversToSchema.js [app-route] (ecmascript)");
Object.defineProperty(exports, "addResolversToSchema", {
    enumerable: true,
    get: function() {
        return addResolversToSchema_js_1.addResolversToSchema;
    }
});
var checkForResolveTypeResolver_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/checkForResolveTypeResolver.js [app-route] (ecmascript)");
Object.defineProperty(exports, "checkForResolveTypeResolver", {
    enumerable: true,
    get: function() {
        return checkForResolveTypeResolver_js_1.checkForResolveTypeResolver;
    }
});
var extendResolversFromInterfaces_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/extendResolversFromInterfaces.js [app-route] (ecmascript)");
Object.defineProperty(exports, "extendResolversFromInterfaces", {
    enumerable: true,
    get: function() {
        return extendResolversFromInterfaces_js_1.extendResolversFromInterfaces;
    }
});
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/makeExecutableSchema.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/types.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/schema/cjs/merge-schemas.js [app-route] (ecmascript)"), exports);
var utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
Object.defineProperty(exports, "extractExtensionsFromSchema", {
    enumerable: true,
    get: function() {
        return utils_1.extractExtensionsFromSchema;
    }
});
}),
"[project]/node_modules/@graphql-tools/merge/cjs/merge-resolvers.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeResolvers = mergeResolvers;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
/**
 * Deep merges multiple resolver definition objects into a single definition.
 * @param resolversDefinitions Resolver definitions to be merged
 * @param options Additional options
 *
 * ```js
 * const { mergeResolvers } = require('@graphql-tools/merge');
 * const clientResolver = require('./clientResolver');
 * const productResolver = require('./productResolver');
 *
 * const resolvers = mergeResolvers([
 *  clientResolver,
 *  productResolver,
 * ]);
 * ```
 *
 * If you don't want to manually create the array of resolver objects, you can
 * also use this function along with loadFiles:
 *
 * ```js
 * const path = require('path');
 * const { mergeResolvers } = require('@graphql-tools/merge');
 * const { loadFilesSync } = require('@graphql-tools/load-files');
 *
 * const resolversArray = loadFilesSync(path.join(__dirname, './resolvers'));
 *
 * const resolvers = mergeResolvers(resolversArray)
 * ```
 */ function mergeResolvers(resolversDefinitions, options) {
    if (!resolversDefinitions || Array.isArray(resolversDefinitions) && resolversDefinitions.length === 0) {
        return {};
    }
    if (!Array.isArray(resolversDefinitions)) {
        return resolversDefinitions;
    }
    if (resolversDefinitions.length === 1) {
        return resolversDefinitions[0] || {};
    }
    const resolvers = new Array();
    for (let resolversDefinition of resolversDefinitions){
        if (Array.isArray(resolversDefinition)) {
            resolversDefinition = mergeResolvers(resolversDefinition);
        }
        if (typeof resolversDefinition === 'object' && resolversDefinition) {
            resolvers.push(resolversDefinition);
        }
    }
    const result = (0, utils_1.mergeDeep)(resolvers, true);
    if (options?.exclusions) {
        for (const exclusion of options.exclusions){
            const [typeName, fieldName] = exclusion.split('.');
            if ([
                '__proto__',
                'constructor',
                'prototype'
            ].includes(typeName) || [
                '__proto__',
                'constructor',
                'prototype'
            ].includes(fieldName)) {
                continue;
            }
            if (!fieldName || fieldName === '*') {
                delete result[typeName];
            } else if (result[typeName]) {
                delete result[typeName][fieldName];
            }
        }
    }
    return result;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/arguments.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeArguments = mergeArguments;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
function mergeArguments(args1, args2, config) {
    const result = deduplicateArguments([
        ...args2,
        ...args1
    ].filter(utils_1.isSome), config);
    if (config && config.sort) {
        result.sort(utils_1.compareNodes);
    }
    return result;
}
function deduplicateArguments(args, config) {
    return args.reduce((acc, current)=>{
        const dupIndex = acc.findIndex((arg)=>arg.name.value === current.name.value);
        if (dupIndex === -1) {
            return acc.concat([
                current
            ]);
        } else if (!config?.reverseArguments) {
            acc[dupIndex] = current;
        }
        return acc;
    }, []);
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeDirectives = mergeDirectives;
exports.mergeDirective = mergeDirective;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
function isRepeatableDirective(directive, directives, repeatableLinkImports) {
    return !!(directives?.[directive.name.value]?.repeatable ?? repeatableLinkImports?.has(directive.name.value));
}
function nameAlreadyExists(name, namesArr) {
    return namesArr.some(({ value })=>value === name.value);
}
function mergeArguments(a1, a2) {
    const result = [];
    for (const argument of [
        ...a2,
        ...a1
    ]){
        const existingIndex = result.findIndex((a)=>a.name.value === argument.name.value);
        if (existingIndex === -1) {
            result.push(argument);
        } else {
            const existingArg = result[existingIndex];
            if (existingArg.value.kind === 'ListValue') {
                const source = existingArg.value.values;
                const target = argument.value.values;
                // merge values of two lists
                existingArg.value = {
                    ...existingArg.value,
                    values: deduplicateLists(source, target, (targetVal, source)=>{
                        const value = targetVal.value;
                        return !value || !source.some((sourceVal)=>sourceVal.value === value);
                    })
                };
            } else {
                existingArg.value = argument.value;
            }
        }
    }
    return result;
}
const matchValues = (a, b)=>{
    if (a.kind === b.kind) {
        switch(a.kind){
            case graphql_1.Kind.LIST:
                return a.values.length === b.values.length && a.values.every((aVal)=>b.values.find((bVal)=>matchValues(aVal, bVal)));
            case graphql_1.Kind.VARIABLE:
            case graphql_1.Kind.NULL:
                return true;
            case graphql_1.Kind.OBJECT:
                return a.fields.length === b.fields.length && a.fields.every((aField)=>b.fields.find((bField)=>aField.name.value === bField.name.value && matchValues(aField.value, bField.value)));
            default:
                return a.value === b.value;
        }
    }
    return false;
};
const isLinkDirective = (directive)=>directive.name.value === 'link';
const getLinkDirectiveURL = (directive)=>{
    const stringValue = isLinkDirective(directive) ? directive.arguments?.find((arg)=>arg.name.value === 'url')?.value : undefined;
    return stringValue?.kind === 'StringValue' ? stringValue.value : undefined;
};
const matchArguments = (a, b)=>a.name.value === b.name.value && a.value.kind === b.value.kind && matchValues(a.value, b.value);
/**
 * Check if a directive is an exact match of another directive based on their
 * arguments.
 */ const matchDirectives = (a, b)=>{
    const matched = a.name.value === b.name.value && (a.arguments === b.arguments || a.arguments?.length === b.arguments?.length && a.arguments?.every((argA)=>b.arguments?.find((argB)=>matchArguments(argA, argB))));
    return !!matched;
};
function mergeDirectives(d1 = [], d2 = [], config, directives) {
    const reverseOrder = config && config.reverseDirectives;
    const asNext = reverseOrder ? d1 : d2;
    const asFirst = reverseOrder ? d2 : d1;
    const result = [];
    for (const directive of [
        ...asNext,
        ...asFirst
    ]){
        if (isRepeatableDirective(directive, directives, config?.repeatableLinkImports)) {
            // look for repeated, identical directives that come before this instance
            // if those exist, return null so that this directive gets removed.
            const exactDuplicate = result.find((d)=>matchDirectives(directive, d));
            if (!exactDuplicate) {
                result.push(directive);
            }
        } else {
            const firstAt = result.findIndex((d)=>d.name.value === directive.name.value);
            if (firstAt === -1) {
                // if did not find a directive with this name on the result set already
                result.push(directive);
            } else {
                if (isLinkDirective(directive) && isLinkDirective(result[firstAt])) {
                    const url1 = getLinkDirectiveURL(directive);
                    const url2 = getLinkDirectiveURL(result[firstAt]);
                    // if both are link directives but with different urls, do not merge them
                    if (url1 && url2 && url1 !== url2) {
                        result.push(directive);
                        continue;
                    }
                }
                // if not repeatable and found directive with the same name already in the result set,
                // then merge the arguments of the existing directive and the new directive
                const mergedArguments = mergeArguments(directive.arguments ?? [], result[firstAt].arguments ?? []);
                result[firstAt] = {
                    ...result[firstAt],
                    arguments: mergedArguments.length === 0 ? undefined : mergedArguments
                };
            }
        }
    }
    return result;
}
function mergeDirective(node, existingNode) {
    if (existingNode) {
        return {
            ...node,
            arguments: deduplicateLists(existingNode.arguments || [], node.arguments || [], (arg, existingArgs)=>!nameAlreadyExists(arg.name, existingArgs.map((a)=>a.name))),
            locations: [
                ...existingNode.locations,
                ...node.locations.filter((name)=>!nameAlreadyExists(name, existingNode.locations))
            ]
        };
    }
    return node;
}
function deduplicateLists(source, target, filterFn) {
    return source.concat(target.filter((val)=>filterFn(val, source)));
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum-values.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeEnumValues = mergeEnumValues;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
function mergeEnumValues(first, second, config, directives) {
    if (config?.consistentEnumMerge) {
        const reversed = [];
        if (first) {
            reversed.push(...first);
        }
        first = second;
        second = reversed;
    }
    const enumValueMap = new Map();
    if (first) {
        for (const firstValue of first){
            enumValueMap.set(firstValue.name.value, firstValue);
        }
    }
    if (second) {
        for (const secondValue of second){
            const enumValue = secondValue.name.value;
            if (enumValueMap.has(enumValue)) {
                const firstValue = enumValueMap.get(enumValue);
                firstValue.description = secondValue.description || firstValue.description;
                firstValue.directives = (0, directives_js_1.mergeDirectives)(secondValue.directives, firstValue.directives, directives);
            } else {
                enumValueMap.set(enumValue, secondValue);
            }
        }
    }
    const result = [
        ...enumValueMap.values()
    ];
    if (config && config.sort) {
        result.sort(utils_1.compareNodes);
    }
    return result;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeEnum = mergeEnum;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const enum_values_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum-values.js [app-route] (ecmascript)");
function mergeEnum(e1, e2, config, directives) {
    if (e2) {
        return {
            name: e1.name,
            description: e1['description'] || e2['description'],
            kind: config?.convertExtensions || e1.kind === 'EnumTypeDefinition' || e2.kind === 'EnumTypeDefinition' ? 'EnumTypeDefinition' : 'EnumTypeExtension',
            loc: e1.loc,
            directives: (0, directives_js_1.mergeDirectives)(e1.directives, e2.directives, config, directives),
            values: (0, enum_values_js_1.mergeEnumValues)(e1.values, e2.values, config)
        };
    }
    return config?.convertExtensions ? {
        ...e1,
        kind: graphql_1.Kind.ENUM_TYPE_DEFINITION
    } : e1;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/utils.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.CompareVal = void 0;
exports.isStringTypes = isStringTypes;
exports.isSourceTypes = isSourceTypes;
exports.extractType = extractType;
exports.isWrappingTypeNode = isWrappingTypeNode;
exports.isListTypeNode = isListTypeNode;
exports.isNonNullTypeNode = isNonNullTypeNode;
exports.printTypeNode = printTypeNode;
exports.defaultStringComparator = defaultStringComparator;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
function isStringTypes(types) {
    return typeof types === 'string';
}
function isSourceTypes(types) {
    return types instanceof graphql_1.Source;
}
function extractType(type) {
    let visitedType = type;
    while(visitedType.kind === graphql_1.Kind.LIST_TYPE || visitedType.kind === 'NonNullType'){
        visitedType = visitedType.type;
    }
    return visitedType;
}
function isWrappingTypeNode(type) {
    return type.kind !== graphql_1.Kind.NAMED_TYPE;
}
function isListTypeNode(type) {
    return type.kind === graphql_1.Kind.LIST_TYPE;
}
function isNonNullTypeNode(type) {
    return type.kind === graphql_1.Kind.NON_NULL_TYPE;
}
function printTypeNode(type) {
    if (isListTypeNode(type)) {
        return `[${printTypeNode(type.type)}]`;
    }
    if (isNonNullTypeNode(type)) {
        return `${printTypeNode(type.type)}!`;
    }
    return type.name.value;
}
var CompareVal;
(function(CompareVal) {
    CompareVal[CompareVal["A_SMALLER_THAN_B"] = -1] = "A_SMALLER_THAN_B";
    CompareVal[CompareVal["A_EQUALS_B"] = 0] = "A_EQUALS_B";
    CompareVal[CompareVal["A_GREATER_THAN_B"] = 1] = "A_GREATER_THAN_B";
})(CompareVal || (exports.CompareVal = CompareVal = {}));
function defaultStringComparator(a, b) {
    if (a == null && b == null) {
        return CompareVal.A_EQUALS_B;
    }
    if (a == null) {
        return CompareVal.A_SMALLER_THAN_B;
    }
    if (b == null) {
        return CompareVal.A_GREATER_THAN_B;
    }
    if (a < b) return CompareVal.A_SMALLER_THAN_B;
    if (a > b) return CompareVal.A_GREATER_THAN_B;
    return CompareVal.A_EQUALS_B;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/fields.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeFields = mergeFields;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const arguments_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/arguments.js [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/utils.js [app-route] (ecmascript)");
function fieldAlreadyExists(fieldsArr, otherField) {
    const resultIndex = fieldsArr.findIndex((field)=>field.name.value === otherField.name.value);
    return [
        resultIndex > -1 ? fieldsArr[resultIndex] : null,
        resultIndex
    ];
}
function mergeFields(type, f1, f2, config, directives) {
    const result = [];
    if (f2 != null) {
        result.push(...f2);
    }
    if (f1 != null) {
        for (const field of f1){
            const [existing, existingIndex] = fieldAlreadyExists(result, field);
            if (existing && !config?.ignoreFieldConflicts) {
                const newField = config?.onFieldTypeConflict && config.onFieldTypeConflict(existing, field, type, config?.throwOnConflict) || preventConflicts(type, existing, field, config?.throwOnConflict);
                newField.arguments = (0, arguments_js_1.mergeArguments)(field['arguments'] || [], existing['arguments'] || [], config);
                newField.directives = (0, directives_js_1.mergeDirectives)(field.directives, existing.directives, config, directives);
                newField.description = field.description || existing.description;
                result[existingIndex] = newField;
            } else {
                result.push(field);
            }
        }
    }
    if (config && config.sort) {
        result.sort(utils_1.compareNodes);
    }
    if (config && config.exclusions) {
        const exclusions = config.exclusions;
        return result.filter((field)=>!exclusions.includes(`${type.name.value}.${field.name.value}`));
    }
    return result;
}
function preventConflicts(type, a, b, ignoreNullability = false) {
    const aType = (0, utils_js_1.printTypeNode)(a.type);
    const bType = (0, utils_js_1.printTypeNode)(b.type);
    if (aType !== bType) {
        const t1 = (0, utils_js_1.extractType)(a.type);
        const t2 = (0, utils_js_1.extractType)(b.type);
        if (t1.name.value !== t2.name.value) {
            throw new Error(`Field "${b.name.value}" already defined with a different type. Declared as "${t1.name.value}", but you tried to override with "${t2.name.value}"`);
        }
        if (!safeChangeForFieldType(a.type, b.type, !ignoreNullability)) {
            throw new Error(`Field '${type.name.value}.${a.name.value}' changed type from '${aType}' to '${bType}'`);
        }
    }
    if ((0, utils_js_1.isNonNullTypeNode)(b.type) && !(0, utils_js_1.isNonNullTypeNode)(a.type)) {
        a.type = b.type;
    }
    return a;
}
function safeChangeForFieldType(oldType, newType, ignoreNullability = false) {
    // both are named
    if (!(0, utils_js_1.isWrappingTypeNode)(oldType) && !(0, utils_js_1.isWrappingTypeNode)(newType)) {
        return oldType.toString() === newType.toString();
    }
    // new is non-null
    if ((0, utils_js_1.isNonNullTypeNode)(newType)) {
        const ofType = (0, utils_js_1.isNonNullTypeNode)(oldType) ? oldType.type : oldType;
        return safeChangeForFieldType(ofType, newType.type);
    }
    // old is non-null
    if ((0, utils_js_1.isNonNullTypeNode)(oldType)) {
        return safeChangeForFieldType(newType, oldType, ignoreNullability);
    }
    // old is list
    if ((0, utils_js_1.isListTypeNode)(oldType)) {
        return (0, utils_js_1.isListTypeNode)(newType) && safeChangeForFieldType(oldType.type, newType.type) || (0, utils_js_1.isNonNullTypeNode)(newType) && safeChangeForFieldType(oldType, newType['type']);
    }
    return false;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/input-type.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeInputType = mergeInputType;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const fields_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/fields.js [app-route] (ecmascript)");
function mergeInputType(node, existingNode, config, directives) {
    if (existingNode) {
        try {
            return {
                name: node.name,
                description: node['description'] || existingNode['description'],
                kind: config?.convertExtensions || node.kind === 'InputObjectTypeDefinition' || existingNode.kind === 'InputObjectTypeDefinition' ? 'InputObjectTypeDefinition' : 'InputObjectTypeExtension',
                loc: node.loc,
                fields: (0, fields_js_1.mergeFields)(node, node.fields, existingNode.fields, config),
                directives: (0, directives_js_1.mergeDirectives)(node.directives, existingNode.directives, config, directives)
            };
        } catch (e) {
            throw new Error(`Unable to merge GraphQL input type "${node.name.value}": ${e.message}`);
        }
    }
    return config?.convertExtensions ? {
        ...node,
        kind: graphql_1.Kind.INPUT_OBJECT_TYPE_DEFINITION
    } : node;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-named-type-array.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeNamedTypeArray = mergeNamedTypeArray;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
function alreadyExists(arr, other) {
    return !!arr.find((i)=>i.name.value === other.name.value);
}
function mergeNamedTypeArray(first = [], second = [], config = {}) {
    const result = [
        ...second,
        ...first.filter((d)=>!alreadyExists(second, d))
    ];
    if (config && config.sort) {
        result.sort(utils_1.compareNodes);
    }
    return result;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/interface.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeInterface = mergeInterface;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const fields_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/fields.js [app-route] (ecmascript)");
const merge_named_type_array_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-named-type-array.js [app-route] (ecmascript)");
function mergeInterface(node, existingNode, config, directives) {
    if (existingNode) {
        try {
            return {
                name: node.name,
                description: node['description'] || existingNode['description'],
                kind: config?.convertExtensions || node.kind === 'InterfaceTypeDefinition' || existingNode.kind === 'InterfaceTypeDefinition' ? 'InterfaceTypeDefinition' : 'InterfaceTypeExtension',
                loc: node.loc,
                fields: (0, fields_js_1.mergeFields)(node, node.fields, existingNode.fields, config, directives),
                directives: (0, directives_js_1.mergeDirectives)(node.directives, existingNode.directives, config, directives),
                interfaces: node['interfaces'] ? (0, merge_named_type_array_js_1.mergeNamedTypeArray)(node['interfaces'], existingNode['interfaces'], config) : undefined
            };
        } catch (e) {
            throw new Error(`Unable to merge GraphQL interface "${node.name.value}": ${e.message}`);
        }
    }
    return config?.convertExtensions ? {
        ...node,
        kind: graphql_1.Kind.INTERFACE_TYPE_DEFINITION
    } : node;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/scalar.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeScalar = mergeScalar;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
function mergeScalar(node, existingNode, config, directives) {
    if (existingNode) {
        return {
            name: node.name,
            description: node['description'] || existingNode['description'],
            kind: config?.convertExtensions || node.kind === 'ScalarTypeDefinition' || existingNode.kind === 'ScalarTypeDefinition' ? 'ScalarTypeDefinition' : 'ScalarTypeExtension',
            loc: node.loc,
            directives: (0, directives_js_1.mergeDirectives)(node.directives, existingNode.directives, config, directives)
        };
    }
    return config?.convertExtensions ? {
        ...node,
        kind: graphql_1.Kind.SCALAR_TYPE_DEFINITION
    } : node;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/schema-def.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.DEFAULT_OPERATION_TYPE_NAME_MAP = void 0;
exports.mergeSchemaDefs = mergeSchemaDefs;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
exports.DEFAULT_OPERATION_TYPE_NAME_MAP = {
    query: 'Query',
    mutation: 'Mutation',
    subscription: 'Subscription'
};
function mergeOperationTypes(opNodeList = [], existingOpNodeList = []) {
    const finalOpNodeList = [];
    for(const opNodeType in exports.DEFAULT_OPERATION_TYPE_NAME_MAP){
        const opNode = opNodeList.find((n)=>n.operation === opNodeType) || existingOpNodeList.find((n)=>n.operation === opNodeType);
        if (opNode) {
            finalOpNodeList.push(opNode);
        }
    }
    return finalOpNodeList;
}
function mergeSchemaDefs(node, existingNode, config, directives) {
    if (existingNode) {
        return {
            kind: node.kind === graphql_1.Kind.SCHEMA_DEFINITION || existingNode.kind === graphql_1.Kind.SCHEMA_DEFINITION ? graphql_1.Kind.SCHEMA_DEFINITION : graphql_1.Kind.SCHEMA_EXTENSION,
            description: node['description'] || existingNode['description'],
            directives: (0, directives_js_1.mergeDirectives)(node.directives, existingNode.directives, config, directives),
            operationTypes: mergeOperationTypes(node.operationTypes, existingNode.operationTypes)
        };
    }
    return config?.convertExtensions ? {
        ...node,
        kind: graphql_1.Kind.SCHEMA_DEFINITION
    } : node;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/type.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeType = mergeType;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const fields_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/fields.js [app-route] (ecmascript)");
const merge_named_type_array_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-named-type-array.js [app-route] (ecmascript)");
function mergeType(node, existingNode, config, directives) {
    if (existingNode) {
        try {
            return {
                name: node.name,
                description: node['description'] || existingNode['description'],
                kind: config?.convertExtensions || node.kind === 'ObjectTypeDefinition' || existingNode.kind === 'ObjectTypeDefinition' ? 'ObjectTypeDefinition' : 'ObjectTypeExtension',
                loc: node.loc,
                fields: (0, fields_js_1.mergeFields)(node, node.fields, existingNode.fields, config, directives),
                directives: (0, directives_js_1.mergeDirectives)(node.directives, existingNode.directives, config, directives),
                interfaces: (0, merge_named_type_array_js_1.mergeNamedTypeArray)(node.interfaces, existingNode.interfaces, config)
            };
        } catch (e) {
            throw new Error(`Unable to merge GraphQL type "${node.name.value}": ${e.message}`);
        }
    }
    return config?.convertExtensions ? {
        ...node,
        kind: graphql_1.Kind.OBJECT_TYPE_DEFINITION
    } : node;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/union.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeUnion = mergeUnion;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const merge_named_type_array_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-named-type-array.js [app-route] (ecmascript)");
function mergeUnion(first, second, config, directives) {
    if (second) {
        return {
            name: first.name,
            description: first['description'] || second['description'],
            // ConstXNode has been introduced in v16 but it is not compatible with XNode so we do `as any` for backwards compatibility
            directives: (0, directives_js_1.mergeDirectives)(first.directives, second.directives, config, directives),
            kind: config?.convertExtensions || first.kind === 'UnionTypeDefinition' || second.kind === 'UnionTypeDefinition' ? graphql_1.Kind.UNION_TYPE_DEFINITION : graphql_1.Kind.UNION_TYPE_EXTENSION,
            loc: first.loc,
            types: (0, merge_named_type_array_js_1.mergeNamedTypeArray)(first.types, second.types, config)
        };
    }
    return config?.convertExtensions ? {
        ...first,
        kind: graphql_1.Kind.UNION_TYPE_DEFINITION
    } : first;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-nodes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.schemaDefSymbol = void 0;
exports.isNamedDefinitionNode = isNamedDefinitionNode;
exports.mergeGraphQLNodes = mergeGraphQLNodes;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const directives_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)");
const enum_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum.js [app-route] (ecmascript)");
const input_type_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/input-type.js [app-route] (ecmascript)");
const interface_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/interface.js [app-route] (ecmascript)");
const scalar_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/scalar.js [app-route] (ecmascript)");
const schema_def_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/schema-def.js [app-route] (ecmascript)");
const type_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/type.js [app-route] (ecmascript)");
const union_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/union.js [app-route] (ecmascript)");
exports.schemaDefSymbol = 'SCHEMA_DEF_SYMBOL';
function isNamedDefinitionNode(definitionNode) {
    return 'name' in definitionNode;
}
function mergeGraphQLNodes(nodes, config, directives = {}) {
    const mergedResultMap = directives;
    for (const nodeDefinition of nodes){
        if (isNamedDefinitionNode(nodeDefinition)) {
            const name = nodeDefinition.name?.value;
            if (config?.commentDescriptions) {
                (0, utils_1.collectComment)(nodeDefinition);
            }
            if (name == null) {
                continue;
            }
            if (config?.exclusions?.includes(name + '.*') || config?.exclusions?.includes(name)) {
                delete mergedResultMap[name];
            } else {
                switch(nodeDefinition.kind){
                    case graphql_1.Kind.OBJECT_TYPE_DEFINITION:
                    case graphql_1.Kind.OBJECT_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, type_js_1.mergeType)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.ENUM_TYPE_DEFINITION:
                    case graphql_1.Kind.ENUM_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, enum_js_1.mergeEnum)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.UNION_TYPE_DEFINITION:
                    case graphql_1.Kind.UNION_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, union_js_1.mergeUnion)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.SCALAR_TYPE_DEFINITION:
                    case graphql_1.Kind.SCALAR_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, scalar_js_1.mergeScalar)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.INPUT_OBJECT_TYPE_DEFINITION:
                    case graphql_1.Kind.INPUT_OBJECT_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, input_type_js_1.mergeInputType)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.INTERFACE_TYPE_DEFINITION:
                    case graphql_1.Kind.INTERFACE_TYPE_EXTENSION:
                        mergedResultMap[name] = (0, interface_js_1.mergeInterface)(nodeDefinition, mergedResultMap[name], config, directives);
                        break;
                    case graphql_1.Kind.DIRECTIVE_DEFINITION:
                        if (mergedResultMap[name]) {
                            const isInheritedFromPrototype = name in {}; // i.e. toString
                            if (isInheritedFromPrototype) {
                                if (!isASTNode(mergedResultMap[name])) {
                                    mergedResultMap[name] = undefined;
                                }
                            }
                        }
                        mergedResultMap[name] = (0, directives_js_1.mergeDirective)(nodeDefinition, mergedResultMap[name]);
                        break;
                }
            }
        } else if (nodeDefinition.kind === graphql_1.Kind.SCHEMA_DEFINITION || nodeDefinition.kind === graphql_1.Kind.SCHEMA_EXTENSION) {
            mergedResultMap[exports.schemaDefSymbol] = (0, schema_def_js_1.mergeSchemaDefs)(nodeDefinition, mergedResultMap[exports.schemaDefSymbol], config);
        }
    }
    return mergedResultMap;
}
function isASTNode(node) {
    return node != null && typeof node === 'object' && 'kind' in node && typeof node.kind === 'string';
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/links.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.resolveImportName = resolveImportName;
exports.extractLinks = extractLinks;
/**
 * A simplified, GraphQL v15 compatible version of
 * https://github.com/graphql-hive/federation-composition/blob/main/src/utils/link/index.ts
 * that does not provide the same safeguards or functionality, but still can determine the
 * correct name of an linked resource.
 */ const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
function namespace(link) {
    return link.as ?? link.url.name;
}
function defaultImport(link) {
    const name = namespace(link);
    return name && `@${name}`;
}
function resolveImportName(link, elementName) {
    if (link.url.name && elementName === `@${link.url.name}`) {
        // @note: default is a directive... So remove the `@`
        return defaultImport(link).substring(1);
    }
    const imported = link.imports.find((i)=>i.name === elementName);
    const resolvedName = imported?.as ?? imported?.name ?? namespaced(namespace(link), elementName);
    // Strip the `@` prefix for directives because in all implementations of mapping or visiting a schema,
    // directive names are not prefixed with `@`. The `@` is only for SDL.
    return resolvedName.startsWith('@') ? resolvedName.substring(1) : resolvedName;
}
function namespaced(namespace, name) {
    if (namespace?.length) {
        if (name.startsWith('@')) {
            return `@${namespace}__${name.substring(1)}`;
        }
        return `${namespace}__${name}`;
    }
    return name;
}
function extractLinks(typeDefs) {
    let links = [];
    for (const definition of typeDefs.definitions){
        if (definition.kind === graphql_1.Kind.SCHEMA_EXTENSION || definition.kind === graphql_1.Kind.SCHEMA_DEFINITION) {
            const defLinks = definition.directives?.filter((directive)=>directive.name.value === 'link');
            const parsedLinks = defLinks?.map((l)=>linkFromArgs(l.arguments ?? [])).filter((l)=>l !== undefined) ?? [];
            links = links.concat(parsedLinks);
            // Federation 1 support... Federation 1 uses "@core" instead of "@link", but behavior is similar enough that
            //  it can be translated.
            const defCores = definition.directives?.filter(({ name })=>name.value === 'core');
            const coreLinks = defCores?.map((c)=>linkFromCoreArgs(c.arguments ?? [])).filter((l)=>l !== undefined);
            if (coreLinks) {
                links = links.concat(...coreLinks);
            }
        }
    }
    return links;
}
function linkFromArgs(args) {
    let url;
    let imports = [];
    let as;
    for (const arg of args){
        switch(arg.name.value){
            case 'url':
                {
                    if (arg.value.kind === graphql_1.Kind.STRING) {
                        url = parseFederationLinkUrl(arg.value.value);
                    }
                    break;
                }
            case 'import':
                {
                    imports = parseImportNode(arg.value);
                    break;
                }
            case 'as':
                {
                    if (arg.value.kind === graphql_1.Kind.STRING) {
                        as = arg.value.value ?? undefined;
                    }
                    break;
                }
            default:
                {
                // ignore. It's not the job of this package to validate. Federation should validate links.
                }
        }
    }
    if (url !== undefined) {
        return {
            url,
            as,
            imports
        };
    }
}
/**
 * Supports federation 1
 */ function linkFromCoreArgs(args) {
    const feature = args.find(({ name, value })=>name.value === 'feature' && value.kind === graphql_1.Kind.STRING);
    if (feature) {
        const url = parseFederationLinkUrl(feature.value.value);
        return {
            url,
            imports: []
        };
    }
}
function parseImportNode(node) {
    if (node.kind === graphql_1.Kind.LIST) {
        const imports = node.values.map((v)=>{
            let namedImport;
            if (v.kind === graphql_1.Kind.STRING) {
                namedImport = {
                    name: v.value
                };
            } else if (v.kind === graphql_1.Kind.OBJECT) {
                let name = '';
                let as;
                for (const f of v.fields){
                    if (f.name.value === 'name') {
                        if (f.value.kind === graphql_1.Kind.STRING) {
                            name = f.value.value;
                        }
                    } else if (f.name.value === 'as') {
                        if (f.value.kind === graphql_1.Kind.STRING) {
                            as = f.value.value;
                        }
                    }
                }
                namedImport = {
                    name,
                    as
                };
            }
            return namedImport;
        });
        return imports.filter((i)=>i !== undefined);
    }
    return [];
}
const VERSION_MATCH = /v(\d{1,3})\.(\d{1,4})/i;
function parseFederationLinkUrl(urlSource) {
    const url = new URL(urlSource);
    const parts = url.pathname.split('/').filter(Boolean);
    const versionOrName = parts[parts.length - 1];
    if (versionOrName) {
        if (VERSION_MATCH.test(versionOrName)) {
            const maybeName = parts[parts.length - 2];
            return {
                identity: url.origin + (maybeName ? `/${parts.slice(0, parts.length - 1).join('/')}` : ''),
                name: maybeName ?? null,
                version: versionOrName
            };
        }
        return {
            identity: `${url.origin}/${parts.join('/')}`,
            name: versionOrName,
            version: null
        };
    }
    return {
        identity: url.origin,
        name: null,
        version: null
    };
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-typedefs.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mergeTypeDefs = mergeTypeDefs;
exports.mergeGraphQLTypes = mergeGraphQLTypes;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const links_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/links.js [app-route] (ecmascript)");
const merge_nodes_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-nodes.js [app-route] (ecmascript)");
const schema_def_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/schema-def.js [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/utils.js [app-route] (ecmascript)");
function mergeTypeDefs(typeSource, config) {
    (0, utils_1.resetComments)();
    const doc = {
        kind: graphql_1.Kind.DOCUMENT,
        definitions: mergeGraphQLTypes(typeSource, {
            useSchemaDefinition: true,
            forceSchemaDefinition: false,
            throwOnConflict: false,
            commentDescriptions: false,
            ...config
        })
    };
    let result;
    if (config?.commentDescriptions) {
        result = (0, utils_1.printWithComments)(doc);
    } else {
        result = doc;
    }
    (0, utils_1.resetComments)();
    return result;
}
function visitTypeSources(typeSource, options, allDirectives = [], allNodes = [], visitedTypeSources = new Set(), repeatableLinkImports = new Set()) {
    const addRepeatable = (name)=>{
        repeatableLinkImports.add(name);
    };
    if (typeSource && !visitedTypeSources.has(typeSource)) {
        visitedTypeSources.add(typeSource);
        if (typeof typeSource === 'function') {
            visitTypeSources(typeSource(), options, allDirectives, allNodes, visitedTypeSources, repeatableLinkImports);
        } else if (Array.isArray(typeSource)) {
            for (const type of typeSource){
                visitTypeSources(type, options, allDirectives, allNodes, visitedTypeSources, repeatableLinkImports);
            }
        } else if ((0, graphql_1.isSchema)(typeSource)) {
            const documentNode = (0, utils_1.getDocumentNodeFromSchema)(typeSource, options);
            visitTypeSources(documentNode.definitions, options, allDirectives, allNodes, visitedTypeSources, repeatableLinkImports);
        } else if ((0, utils_js_1.isStringTypes)(typeSource) || (0, utils_js_1.isSourceTypes)(typeSource)) {
            const documentNode = (0, graphql_1.parse)(typeSource, options);
            visitTypeSources(documentNode.definitions, options, allDirectives, allNodes, visitedTypeSources, repeatableLinkImports);
        } else if (typeof typeSource === 'object' && (0, graphql_1.isDefinitionNode)(typeSource)) {
            const links = (0, links_js_1.extractLinks)({
                definitions: [
                    typeSource
                ],
                kind: graphql_1.Kind.DOCUMENT
            });
            const federationUrl = 'https://specs.apollo.dev/federation';
            const linkUrl = 'https://specs.apollo.dev/link';
            /**
             * Official Federated imports are special because they can be referenced without specifyin the import.
             * To handle this case, we must prepare a list of all the possible valid usages to check against.
             * Note that this versioning is not technically correct, since some definitions are after v2.0.
             * But this is enough information to be comfortable not blocking the imports at this phase. It's
             * the job of the composer to validate the versions.
             * */ const federationLink = links.find((l)=>l.url.identity === federationUrl);
            if (federationLink) {
                addRepeatable((0, links_js_1.resolveImportName)(federationLink, '@composeDirective'));
                addRepeatable((0, links_js_1.resolveImportName)(federationLink, '@key'));
            }
            const linkLink = links.find((l)=>l.url.identity === linkUrl);
            if (linkLink) {
                addRepeatable((0, links_js_1.resolveImportName)(linkLink, '@link'));
            }
            if (typeSource.kind === graphql_1.Kind.DIRECTIVE_DEFINITION) {
                allDirectives.push(typeSource);
            } else {
                allNodes.push(typeSource);
            }
        } else if ((0, utils_1.isDocumentNode)(typeSource)) {
            visitTypeSources(typeSource.definitions, options, allDirectives, allNodes, visitedTypeSources, repeatableLinkImports);
        } else {
            throw new Error(`typeDefs must contain only strings, documents, schemas, or functions, got ${typeof typeSource}`);
        }
    }
    return {
        allDirectives,
        allNodes,
        repeatableLinkImports
    };
}
function mergeGraphQLTypes(typeSource, config) {
    (0, utils_1.resetComments)();
    const { allDirectives, allNodes, repeatableLinkImports } = visitTypeSources(typeSource, config);
    const mergedDirectives = (0, merge_nodes_js_1.mergeGraphQLNodes)(allDirectives, config);
    config.repeatableLinkImports = repeatableLinkImports;
    const mergedNodes = (0, merge_nodes_js_1.mergeGraphQLNodes)(allNodes, config, mergedDirectives);
    if (config?.useSchemaDefinition) {
        // XXX: right now we don't handle multiple schema definitions
        const schemaDef = mergedNodes[merge_nodes_js_1.schemaDefSymbol] || {
            kind: graphql_1.Kind.SCHEMA_DEFINITION,
            operationTypes: []
        };
        const operationTypes = schemaDef.operationTypes;
        for(const opTypeDefNodeType in schema_def_js_1.DEFAULT_OPERATION_TYPE_NAME_MAP){
            const opTypeDefNode = operationTypes.find((operationType)=>operationType.operation === opTypeDefNodeType);
            if (!opTypeDefNode) {
                const possibleRootTypeName = schema_def_js_1.DEFAULT_OPERATION_TYPE_NAME_MAP[opTypeDefNodeType];
                const existingPossibleRootType = mergedNodes[possibleRootTypeName];
                if (existingPossibleRootType != null && existingPossibleRootType.name != null) {
                    operationTypes.push({
                        kind: graphql_1.Kind.OPERATION_TYPE_DEFINITION,
                        type: {
                            kind: graphql_1.Kind.NAMED_TYPE,
                            name: existingPossibleRootType.name
                        },
                        operation: opTypeDefNodeType
                    });
                }
            }
        }
        if (schemaDef?.operationTypes?.length != null && schemaDef.operationTypes.length > 0) {
            mergedNodes[merge_nodes_js_1.schemaDefSymbol] = schemaDef;
        }
    }
    if (config?.forceSchemaDefinition && !mergedNodes[merge_nodes_js_1.schemaDefSymbol]?.operationTypes?.length) {
        mergedNodes[merge_nodes_js_1.schemaDefSymbol] = {
            kind: graphql_1.Kind.SCHEMA_DEFINITION,
            operationTypes: [
                {
                    kind: graphql_1.Kind.OPERATION_TYPE_DEFINITION,
                    operation: 'query',
                    type: {
                        kind: graphql_1.Kind.NAMED_TYPE,
                        name: {
                            kind: graphql_1.Kind.NAME,
                            value: 'Query'
                        }
                    }
                }
            ]
        };
    }
    const mergedNodeDefinitions = Object.values(mergedNodes);
    if (config?.sort) {
        const sortFn = typeof config.sort === 'function' ? config.sort : utils_js_1.defaultStringComparator;
        mergedNodeDefinitions.sort((a, b)=>sortFn(a.name?.value, b.name?.value));
    }
    return mergedNodeDefinitions;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
const tslib_1 = __turbopack_context__.r("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/arguments.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/directives.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum-values.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/enum.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/fields.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/input-type.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/interface.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-named-type-array.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-nodes.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/merge-typedefs.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/scalar.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/type.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/union.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/utils.js [app-route] (ecmascript)"), exports);
}),
"[project]/node_modules/@graphql-tools/merge/cjs/extensions.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.extractExtensionsFromSchema = void 0;
exports.mergeExtensions = mergeExtensions;
exports.applyExtensions = applyExtensions;
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
var utils_2 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
Object.defineProperty(exports, "extractExtensionsFromSchema", {
    enumerable: true,
    get: function() {
        return utils_2.extractExtensionsFromSchema;
    }
});
function mergeExtensions(extensions) {
    return (0, utils_1.mergeDeep)(extensions, false, true);
}
function applyExtensionObject(obj, extensions) {
    if (!obj || !extensions || extensions === obj.extensions) {
        return;
    }
    if (!obj.extensions) {
        obj.extensions = extensions;
        return;
    }
    obj.extensions = (0, utils_1.mergeDeep)([
        obj.extensions,
        extensions
    ], false, true);
}
function applyExtensions(schema, extensions) {
    applyExtensionObject(schema, extensions.schemaExtensions);
    for (const [typeName, data] of Object.entries(extensions.types || {})){
        const type = schema.getType(typeName);
        if (type) {
            applyExtensionObject(type, data.extensions);
            if (data.type === 'object' || data.type === 'interface') {
                for (const [fieldName, fieldData] of Object.entries(data.fields)){
                    const field = type.getFields()[fieldName];
                    if (field) {
                        applyExtensionObject(field, fieldData.extensions);
                        for (const [arg, argData] of Object.entries(fieldData.arguments)){
                            applyExtensionObject(field.args.find((a)=>a.name === arg), argData);
                        }
                    }
                }
            } else if (data.type === 'input') {
                for (const [fieldName, fieldData] of Object.entries(data.fields)){
                    const field = type.getFields()[fieldName];
                    applyExtensionObject(field, fieldData.extensions);
                }
            } else if (data.type === 'enum') {
                for (const [valueName, valueData] of Object.entries(data.values)){
                    const value = type.getValue(valueName);
                    applyExtensionObject(value, valueData);
                }
            }
        }
    }
    return schema;
}
}),
"[project]/node_modules/@graphql-tools/merge/cjs/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
const tslib_1 = __turbopack_context__.r("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/merge-resolvers.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/typedefs-mergers/index.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/merge/cjs/extensions.js [app-route] (ecmascript)"), exports);
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/coerceError.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.coerceError = coerceError;
function coerceError(error) {
    if (error instanceof Error) {
        return error;
    }
    if (typeof error === 'object' && error != null) {
        if ('message' in error && typeof error.message === 'string') {
            let errorOptions;
            if ('cause' in error) {
                errorOptions = {
                    cause: error.cause
                };
            }
            const coercedError = new Error(error.message, errorOptions);
            if ('stack' in error && typeof error.stack === 'string') {
                coercedError.stack = error.stack;
            }
            if ('name' in error && typeof error.name === 'string') {
                coercedError.name = error.name;
            }
            return coercedError;
        }
    }
    return new Error(String(error));
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/flattenAsyncIterable.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.flattenAsyncIterable = flattenAsyncIterable;
const disposablestack_1 = __turbopack_context__.r("[project]/node_modules/@whatwg-node/disposablestack/cjs/index.js [app-route] (ecmascript)");
/**
 * Given an AsyncIterable of AsyncIterables, flatten all yielded results into a
 * single AsyncIterable.
 */ function flattenAsyncIterable(iterable) {
    // You might think this whole function could be replaced with
    //
    //    async function* flattenAsyncIterable(iterable) {
    //      for await (const subIterator of iterable) {
    //        yield* subIterator;
    //      }
    //    }
    //
    // but calling `.return()` on the iterator it returns won't interrupt the `for await`.
    const topIterator = iterable[Symbol.asyncIterator]();
    let currentNestedIterator;
    let waitForCurrentNestedIterator;
    let done = false;
    async function next() {
        if (done) {
            return {
                value: undefined,
                done: true
            };
        }
        try {
            if (!currentNestedIterator) {
                // Somebody else is getting it already.
                if (waitForCurrentNestedIterator) {
                    await waitForCurrentNestedIterator;
                    return await next();
                }
                // Nobody else is getting it. We should!
                let resolve;
                waitForCurrentNestedIterator = new Promise((r)=>{
                    resolve = r;
                });
                const topIteratorResult = await topIterator.next();
                if (topIteratorResult.done) {
                    // Given that done only ever transitions from false to true,
                    // require-atomic-updates is being unnecessarily cautious.
                    done = true;
                    return await next();
                }
                // eslint is making a reasonable point here, but we've explicitly protected
                // ourself from the race condition by ensuring that only the single call
                // that assigns to waitForCurrentNestedIterator is allowed to assign to
                // currentNestedIterator or waitForCurrentNestedIterator.
                currentNestedIterator = topIteratorResult.value[Symbol.asyncIterator]();
                waitForCurrentNestedIterator = undefined;
                resolve();
                return await next();
            }
            const rememberCurrentNestedIterator = currentNestedIterator;
            const nestedIteratorResult = await currentNestedIterator.next();
            if (!nestedIteratorResult.done) {
                return nestedIteratorResult;
            }
            // The nested iterator is done. If it's still the current one, make it not
            // current. (If it's not the current one, somebody else has made us move on.)
            if (currentNestedIterator === rememberCurrentNestedIterator) {
                currentNestedIterator = undefined;
            }
            return await next();
        } catch (err) {
            done = true;
            throw err;
        }
    }
    return {
        next,
        async return () {
            done = true;
            await Promise.all([
                currentNestedIterator?.return?.(),
                topIterator.return?.()
            ]);
            return {
                value: undefined,
                done: true
            };
        },
        async throw (error) {
            done = true;
            await Promise.all([
                currentNestedIterator?.throw?.(error),
                topIterator.throw?.(error)
            ]);
            /* c8 ignore next */ throw error;
        },
        [Symbol.asyncIterator] () {
            return this;
        },
        async [disposablestack_1.DisposableSymbols.asyncDispose] () {
            done = true;
            await Promise.all([
                currentNestedIterator?.[disposablestack_1.DisposableSymbols.asyncDispose]?.(),
                topIterator?.[disposablestack_1.DisposableSymbols.asyncDispose]?.()
            ]);
        }
    };
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/invariant.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.invariant = invariant;
function invariant(condition, message) {
    if (!condition) {
        throw new Error(message != null ? message : 'Unexpected invariant triggered.');
    }
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/promiseForObject.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.promiseForObject = promiseForObject;
const promise_helpers_1 = __turbopack_context__.r("[project]/node_modules/@whatwg-node/promise-helpers/cjs/index.js [app-route] (ecmascript)");
/**
 * This function transforms a JS object `Record<string, Promise<T>>` into
 * a `Promise<Record<string, T>>`
 *
 * This is akin to bluebird's `Promise.props`, but implemented only using
 * `Promise.all` so it will work with any implementation of ES6 promises.
 */ function promiseForObject(object, signal, signalPromise) {
    signal?.throwIfAborted();
    const resolvedObject = Object.create(null);
    const promises = [];
    for(const key in object){
        const valueSet$ = (0, promise_helpers_1.handleMaybePromise)(()=>object[key], (resolvedValue)=>{
            resolvedObject[key] = resolvedValue;
        });
        if ((0, promise_helpers_1.isPromise)(valueSet$)) {
            promises.push(valueSet$);
        }
    }
    if (!promises.length) {
        return resolvedObject;
    }
    const promiseAll = promises.length === 1 ? promises[0] : Promise.all(promises);
    if (signalPromise) {
        return Promise.race([
            signalPromise,
            promiseAll
        ]).then(()=>resolvedObject);
    }
    return promiseAll.then(()=>resolvedObject);
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/values.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getVariableValues = getVariableValues;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
/**
 * Prepares an object map of variableValues of the correct type based on the
 * provided variable definitions and arbitrary input. If the input cannot be
 * parsed to match the variable definitions, a GraphQLError will be thrown.
 *
 * Note: The returned value is a plain Object with a prototype, since it is
 * exposed to user code. Care should be taken to not pull values from the
 * Object prototype.
 */ function getVariableValues(schema, varDefNodes, inputs, options) {
    const errors = [];
    const maxErrors = options?.maxErrors;
    try {
        const coerced = coerceVariableValues(schema, varDefNodes, inputs, (error)=>{
            if (maxErrors != null && errors.length >= maxErrors) {
                throw (0, utils_1.createGraphQLError)('Too many errors processing variables, error limit reached. Execution aborted.');
            }
            errors.push(error);
        });
        if (errors.length === 0) {
            return {
                coerced
            };
        }
    } catch (error) {
        errors.push(error);
    }
    return {
        errors
    };
}
function coerceVariableValues(schema, varDefNodes, inputs, onError) {
    const coercedValues = {};
    for (const varDefNode of varDefNodes){
        const varName = varDefNode.variable.name.value;
        const varType = (0, graphql_1.typeFromAST)(schema, varDefNode.type);
        if (!(0, graphql_1.isInputType)(varType)) {
            // Must use input types for variables. This should be caught during
            // validation, however is checked again here for safety.
            const varTypeStr = (0, graphql_1.print)(varDefNode.type);
            onError((0, utils_1.createGraphQLError)(`Variable "$${varName}" expected value of type "${varTypeStr}" which cannot be used as an input type.`, {
                nodes: varDefNode.type
            }));
            continue;
        }
        if (!(0, utils_1.hasOwnProperty)(inputs, varName)) {
            if (varDefNode.defaultValue) {
                coercedValues[varName] = (0, graphql_1.valueFromAST)(varDefNode.defaultValue, varType);
            } else if ((0, graphql_1.isNonNullType)(varType)) {
                const varTypeStr = (0, utils_1.inspect)(varType);
                onError((0, utils_1.createGraphQLError)(`Variable "$${varName}" of required type "${varTypeStr}" was not provided.`, {
                    nodes: varDefNode
                }));
            }
            continue;
        }
        const value = inputs[varName];
        if (value === null && (0, graphql_1.isNonNullType)(varType)) {
            const varTypeStr = (0, utils_1.inspect)(varType);
            onError((0, utils_1.createGraphQLError)(`Variable "$${varName}" of non-null type "${varTypeStr}" must not be null.`, {
                nodes: varDefNode
            }));
            continue;
        }
        coercedValues[varName] = (0, graphql_1.coerceInputValue)(value, varType, (path, invalidValue, error)=>{
            let prefix = `Variable "$${varName}" got invalid value ` + (0, utils_1.inspect)(invalidValue);
            if (path.length > 0) {
                prefix += ` at "${varName}${(0, utils_1.printPathArray)(path)}"`;
            }
            onError((0, utils_1.createGraphQLError)(prefix + '; ' + error.message, {
                nodes: varDefNode,
                originalError: error
            }));
        });
    }
    return coercedValues;
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/execute.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.defaultFieldResolver = exports.defaultTypeResolver = exports.CRITICAL_ERROR = exports.getFragmentsFromDocument = void 0;
exports.execute = execute;
exports.executeSync = executeSync;
exports.assertValidExecutionArguments = assertValidExecutionArguments;
exports.buildExecutionContext = buildExecutionContext;
exports.buildResolveInfo = buildResolveInfo;
exports.subscribe = subscribe;
exports.isIncrementalResults = isIncrementalResults;
exports.flattenIncrementalResults = flattenIncrementalResults;
exports.getFieldDef = getFieldDef;
exports.isIncrementalResult = isIncrementalResult;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const disposablestack_1 = __turbopack_context__.r("[project]/node_modules/@whatwg-node/disposablestack/cjs/index.js [app-route] (ecmascript)");
const promise_helpers_1 = __turbopack_context__.r("[project]/node_modules/@whatwg-node/promise-helpers/cjs/index.js [app-route] (ecmascript)");
const coerceError_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/coerceError.js [app-route] (ecmascript)");
const flattenAsyncIterable_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/flattenAsyncIterable.js [app-route] (ecmascript)");
const invariant_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/invariant.js [app-route] (ecmascript)");
const promiseForObject_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/promiseForObject.js [app-route] (ecmascript)");
const values_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/values.js [app-route] (ecmascript)");
/**
 * A memoized collection of relevant subfields with regard to the return
 * type. Memoizing ensures the subfields are not repeatedly calculated, which
 * saves overhead when resolving lists of values.
 */ const collectSubfields = (0, utils_1.memoize3)((exeContext, returnType, fieldNodes)=>(0, utils_1.collectSubFields)(exeContext.schema, exeContext.fragments, exeContext.variableValues, returnType, fieldNodes));
/**
 * Implements the "Executing requests" section of the GraphQL specification,
 * including `@defer` and `@stream` as proposed in
 * https://github.com/graphql/graphql-spec/pull/742
 *
 * This function returns a Promise of an IncrementalExecutionResults
 * object. This object either consists of a single ExecutionResult, or an
 * object containing an `initialResult` and a stream of `subsequentResults`.
 *
 * If the arguments to this function do not result in a legal execution context,
 * a GraphQLError will be thrown immediately explaining the invalid input.
 */ function execute(args) {
    // If a valid execution context cannot be created due to incorrect arguments,
    // a "Response" with only errors is returned.
    const exeContext = buildExecutionContext(args);
    // Return early errors if execution context failed.
    if (!('schema' in exeContext)) {
        return {
            errors: exeContext.map((e)=>{
                Object.defineProperty(e, 'extensions', {
                    value: {
                        ...e.extensions,
                        http: {
                            ...e.extensions?.['http'] || {},
                            status: 400
                        }
                    }
                });
                return e;
            })
        };
    }
    return executeImpl(exeContext);
}
function executeImpl(exeContext) {
    exeContext.signal?.throwIfAborted();
    // Return a Promise that will eventually resolve to the data described by
    // The "Response" section of the GraphQL specification.
    //
    // If errors are encountered while executing a GraphQL field, only that
    // field and its descendants will be omitted, and sibling fields will still
    // be executed. An execution which encounters errors will still result in a
    // resolved Promise.
    //
    // Errors from sub-fields of a NonNull type may propagate to the top level,
    // at which point we still log the error and null the parent field, which
    // in this case is the entire response.
    return (0, promise_helpers_1.handleMaybePromise)(()=>executeOperation(exeContext), (data)=>{
        const initialResult = buildResponse(data, exeContext.errors);
        if (exeContext.subsequentPayloads.size > 0) {
            return {
                initialResult: {
                    ...initialResult,
                    hasNext: true
                },
                subsequentResults: yieldSubsequentPayloads(exeContext)
            };
        }
        return initialResult;
    }, (error)=>{
        exeContext.signal?.throwIfAborted();
        if (error.errors) {
            exeContext.errors.push(...error.errors);
        } else {
            exeContext.errors.push(error);
        }
        return buildResponse(null, exeContext.errors);
    });
}
/**
 * Also implements the "Executing requests" section of the GraphQL specification.
 * However, it guarantees to complete synchronously (or throw an error) assuming
 * that all field resolvers are also synchronous.
 */ function executeSync(args) {
    const result = execute(args);
    // Assert that the execution was synchronous.
    if ((0, utils_1.isPromise)(result) || 'initialResult' in result) {
        throw new Error('GraphQL execution failed to complete synchronously.');
    }
    return result;
}
/**
 * Given a completed execution context and data, build the `{ errors, data }`
 * response defined by the "Response" section of the GraphQL specification.
 */ function buildResponse(data, errors) {
    return errors.length === 0 ? {
        data
    } : {
        errors,
        data
    };
}
/**
 * Essential assertions before executing to provide developer feedback for
 * improper use of the GraphQL library.
 *
 * @internal
 */ function assertValidExecutionArguments(schema, document, rawVariableValues) {
    console.assert(!!document, 'Must provide document.');
    // If the schema used for execution is invalid, throw an error.
    (0, graphql_1.assertValidSchema)(schema);
    // Variables, if provided, must be an object.
    console.assert(rawVariableValues == null || (0, utils_1.isObjectLike)(rawVariableValues), 'Variables must be provided as an Object where each property is a variable value. Perhaps look to see if an unparsed JSON string was provided.');
}
exports.getFragmentsFromDocument = (0, utils_1.memoize1)(function getFragmentsFromDocument(document) {
    const fragments = Object.create(null);
    for (const definition of document.definitions){
        if (definition.kind === graphql_1.Kind.FRAGMENT_DEFINITION) {
            fragments[definition.name.value] = definition;
        }
    }
    return fragments;
});
/**
 * Constructs a ExecutionContext object from the arguments passed to
 * execute, which we will pass throughout the other execution methods.
 *
 * Throws a GraphQLError if a valid execution context cannot be created.
 *
 * TODO: consider no longer exporting this function
 * @internal
 */ function buildExecutionContext(args) {
    const { schema, document, rootValue, contextValue, variableValues: rawVariableValues, operationName, fieldResolver, typeResolver, subscribeFieldResolver, signal, schemaCoordinateInErrors } = args;
    signal?.throwIfAborted();
    // If the schema used for execution is invalid, throw an error.
    (0, graphql_1.assertValidSchema)(schema);
    const fragments = (0, exports.getFragmentsFromDocument)(document);
    let operation;
    for (const definition of document.definitions){
        switch(definition.kind){
            case graphql_1.Kind.OPERATION_DEFINITION:
                if (operationName == null) {
                    if (operation !== undefined) {
                        return [
                            (0, utils_1.createGraphQLError)('Must provide operation name if query contains multiple operations.', {
                                extensions: {
                                    code: 'OPERATION_RESOLUTION_FAILURE'
                                }
                            })
                        ];
                    }
                    operation = definition;
                } else if (definition.name?.value === operationName) {
                    operation = definition;
                }
                break;
            default:
        }
    }
    if (operation == null) {
        if (operationName != null) {
            return [
                (0, utils_1.createGraphQLError)(`Unknown operation named "${operationName}".`, {
                    extensions: {
                        code: 'OPERATION_RESOLUTION_FAILURE'
                    }
                })
            ];
        }
        return [
            (0, utils_1.createGraphQLError)('Must provide an operation.', {
                extensions: {
                    code: 'OPERATION_RESOLUTION_FAILURE'
                }
            })
        ];
    }
    // FIXME: https://github.com/graphql/graphql-js/issues/2203
    /* c8 ignore next */ const variableDefinitions = operation.variableDefinitions ?? [];
    const coercedVariableValues = (0, values_js_1.getVariableValues)(schema, variableDefinitions, rawVariableValues ?? {}, {
        maxErrors: 50
    });
    if (coercedVariableValues.errors) {
        return coercedVariableValues.errors;
    }
    signal?.throwIfAborted();
    let onSignalAbort;
    let signalPromise;
    if (signal) {
        const listeners = new Set();
        const signalDeferred = (0, promise_helpers_1.createDeferredPromise)();
        signalPromise = signalDeferred.promise;
        const sharedListener = ()=>{
            signalDeferred.reject(signal.reason);
            signal.removeEventListener('abort', sharedListener);
        };
        signal.addEventListener('abort', sharedListener, {
            once: true
        });
        signalPromise.catch(()=>{
            for (const listener of listeners){
                listener();
            }
            listeners.clear();
        });
        onSignalAbort = (handler)=>{
            listeners.add(handler);
        };
    }
    return {
        schema,
        fragments,
        rootValue,
        contextValue,
        operation,
        variableValues: coercedVariableValues.coerced,
        fieldResolver: fieldResolver ?? exports.defaultFieldResolver,
        typeResolver: typeResolver ?? exports.defaultTypeResolver,
        subscribeFieldResolver: subscribeFieldResolver ?? exports.defaultFieldResolver,
        subsequentPayloads: new Set(),
        errors: [],
        signal,
        onSignalAbort,
        signalPromise,
        schemaCoordinateInErrors
    };
}
function buildPerEventExecutionContext(exeContext, payload) {
    return {
        ...exeContext,
        rootValue: payload,
        subsequentPayloads: new Set(),
        errors: []
    };
}
/**
 * Implements the "Executing operations" section of the spec.
 */ function executeOperation(exeContext) {
    const { operation, schema, fragments, variableValues, rootValue } = exeContext;
    const rootType = (0, utils_1.getDefinedRootType)(schema, operation.operation, [
        operation
    ]);
    if (rootType == null) {
        (0, utils_1.createGraphQLError)(`Schema is not configured to execute ${operation.operation} operation.`, {
            nodes: operation
        });
    }
    const { fields: rootFields, patches } = (0, utils_1.collectFields)(schema, fragments, variableValues, rootType, operation.selectionSet);
    const path = undefined;
    let result;
    if (operation.operation === 'mutation') {
        result = executeFieldsSerially(exeContext, rootType, rootValue, path, rootFields);
    } else {
        result = executeFields(exeContext, rootType, rootValue, path, rootFields);
    }
    for (const patch of patches){
        const { label, fields: patchFields } = patch;
        executeDeferredFragment(exeContext, rootType, rootValue, patchFields, label, path);
    }
    return result;
}
/**
 * Implements the "Executing selection sets" section of the spec
 * for fields that must be executed serially.
 */ function executeFieldsSerially(exeContext, parentType, sourceValue, path, fields) {
    return (0, utils_1.promiseReduce)(fields, (results, [responseName, fieldNodes])=>{
        const fieldPath = (0, utils_1.addPath)(path, responseName, parentType.name);
        exeContext.signal?.throwIfAborted();
        return (0, promise_helpers_1.handleMaybePromise)(()=>executeField(exeContext, parentType, sourceValue, fieldNodes, fieldPath), (result)=>{
            if (result === undefined) {
                return results;
            }
            results[responseName] = result;
            return results;
        });
    }, Object.create(null));
}
/**
 * Implements the "Executing selection sets" section of the spec
 * for fields that may be executed in parallel.
 */ function executeFields(exeContext, parentType, sourceValue, path, fields, asyncPayloadRecord) {
    const results = Object.create(null);
    let containsPromise = false;
    try {
        for (const [responseName, fieldNodes] of fields){
            exeContext.signal?.throwIfAborted();
            const fieldPath = (0, utils_1.addPath)(path, responseName, parentType.name);
            const result = executeField(exeContext, parentType, sourceValue, fieldNodes, fieldPath, asyncPayloadRecord);
            if (result !== undefined) {
                results[responseName] = result;
                if ((0, utils_1.isPromise)(result)) {
                    containsPromise = true;
                }
            }
        }
    } catch (error) {
        if (error !== exeContext.signal?.reason && containsPromise) {
            // Ensure that any promises returned by other fields are handled, as they may also reject.
            return (0, promise_helpers_1.handleMaybePromise)(()=>(0, promiseForObject_js_1.promiseForObject)(results, exeContext.signal), ()=>{
                throw error;
            }, ()=>{
                throw error;
            });
        }
        throw error;
    }
    // If there are no promises, we can just return the object
    if (!containsPromise) {
        return results;
    }
    // Otherwise, results is a map from field name to the result of resolving that
    // field, which is possibly a promise. Return a promise that will return this
    // same map, but with any promises replaced with the values they resolved to.
    return (0, promiseForObject_js_1.promiseForObject)(results, exeContext.signal, exeContext.signalPromise);
}
/**
 * Implements the "Executing fields" section of the spec
 * In particular, this function figures out the value that the field returns by
 * calling its resolve function, then calls completeValue to complete promises,
 * serialize scalars, or execute the sub-selection-set for objects.
 */ function executeField(exeContext, parentType, source, fieldNodes, path, asyncPayloadRecord) {
    const errors = asyncPayloadRecord?.errors ?? exeContext.errors;
    const fieldDef = getFieldDef(exeContext.schema, parentType, fieldNodes[0]);
    if (!fieldDef) {
        return;
    }
    const returnType = fieldDef.type;
    const resolveFn = fieldDef.resolve ?? exeContext.fieldResolver;
    const info = buildResolveInfo(exeContext, fieldDef, fieldNodes, parentType, path);
    // Get the resolve function, regardless of if its result is normal or abrupt (error).
    try {
        exeContext.signal?.throwIfAborted();
        // Build a JS object of arguments from the field.arguments AST, using the
        // variables scope to fulfill any variable references.
        // TODO: find a way to memoize, in case this field is within a List type.
        const args = (0, utils_1.getArgumentValues)(fieldDef, fieldNodes[0], exeContext.variableValues);
        // The resolve function's optional third argument is a context value that
        // is provided to every resolve function within an execution. It is commonly
        // used to represent an authenticated user, or request-specific caches.
        const contextValue = exeContext.contextValue;
        const result = resolveFn(source, args, contextValue, info);
        let completed;
        if ((0, utils_1.isPromise)(result)) {
            completed = result.then((resolved)=>completeValue(exeContext, returnType, fieldNodes, info, path, resolved, asyncPayloadRecord));
        } else {
            completed = completeValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord);
        }
        if ((0, utils_1.isPromise)(completed)) {
            // Note: we don't rely on a `catch` method, but we do expect "thenable"
            // to take a second callback for the error case.
            return completed.then(undefined, (rawError)=>{
                if (rawError instanceof AggregateError) {
                    let result;
                    for (let rawErrorItem of rawError.errors){
                        rawErrorItem = (0, coerceError_js_1.coerceError)(rawErrorItem);
                        const error = (0, utils_1.locatedError)(rawErrorItem, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
                        result = handleFieldError(error, returnType, errors);
                        filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
                    }
                    return result;
                }
                rawError = (0, coerceError_js_1.coerceError)(rawError);
                const error = (0, utils_1.locatedError)(rawError, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
                const handledError = handleFieldError(error, returnType, errors);
                filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
                return handledError;
            });
        }
        return completed;
    } catch (rawError) {
        if (rawError instanceof AggregateError) {
            let result;
            for (let rawErrorItem of rawError.errors){
                rawErrorItem = (0, coerceError_js_1.coerceError)(rawErrorItem);
                const error = (0, utils_1.locatedError)(rawErrorItem, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
                result = handleFieldError(error, returnType, errors);
                filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
            }
            return result;
        }
        const coercedError = (0, coerceError_js_1.coerceError)(rawError);
        const error = (0, utils_1.locatedError)(coercedError, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
        const handledError = handleFieldError(error, returnType, errors);
        filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
        return handledError;
    }
}
/**
 * TODO: consider no longer exporting this function
 * @internal
 */ function buildResolveInfo(exeContext, fieldDef, fieldNodes, parentType, path) {
    // The resolve function's optional fourth argument is a collection of
    // information about the current execution state.
    return {
        fieldName: fieldDef.name,
        fieldNodes,
        returnType: fieldDef.type,
        parentType,
        path,
        schema: exeContext.schema,
        fragments: exeContext.fragments,
        rootValue: exeContext.rootValue,
        operation: exeContext.operation,
        variableValues: exeContext.variableValues,
        signal: exeContext.signal
    };
}
exports.CRITICAL_ERROR = 'CRITICAL_ERROR';
function handleFieldError(error, returnType, errors) {
    // If the field type is non-nullable, then it is resolved without any
    // protection from errors, however it still properly locates the error.
    if ((0, graphql_1.isNonNullType)(returnType)) {
        throw error;
    }
    if (error.extensions?.[exports.CRITICAL_ERROR]) {
        throw error;
    }
    // Otherwise, error protection is applied, logging the error and resolving
    // a null value for this field if one is encountered.
    errors.push(error);
    return null;
}
/**
 * Implements the instructions for completeValue as defined in the
 * "Value Completion" section of the spec.
 *
 * If the field type is Non-Null, then this recursively completes the value
 * for the inner type. It throws a field error if that completion returns null,
 * as per the "Nullability" section of the spec.
 *
 * If the field type is a List, then this recursively completes the value
 * for the inner type on each item in the list.
 *
 * If the field type is a Scalar or Enum, ensures the completed value is a legal
 * value of the type by calling the `serialize` method of GraphQL type
 * definition.
 *
 * If the field is an abstract type, determine the runtime type of the value
 * and then complete based on that type
 *
 * Otherwise, the field type expects a sub-selection set, and will complete the
 * value by executing all sub-selections.
 */ function completeValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord) {
    // If result is an Error, throw a located error.
    if (result instanceof Error) {
        throw result;
    }
    // If field type is NonNull, complete for inner type, and throw field error
    // if result is null.
    if ((0, graphql_1.isNonNullType)(returnType)) {
        const completed = completeValue(exeContext, returnType.ofType, fieldNodes, info, path, result, asyncPayloadRecord);
        if (completed === null) {
            throw new Error(`Cannot return null for non-nullable field ${info.parentType.name}.${info.fieldName}.`);
        }
        return completed;
    }
    // If result value is null or undefined then return null.
    if (result == null) {
        return null;
    }
    // If field type is List, complete each item in the list with the inner type
    if ((0, graphql_1.isListType)(returnType)) {
        return completeListValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord);
    }
    // If field type is a leaf type, Scalar or Enum, serialize to a valid value,
    // returning null if serialization is not possible.
    if ((0, graphql_1.isLeafType)(returnType)) {
        return completeLeafValue(returnType, result);
    }
    // If field type is an abstract type, Interface or Union, determine the
    // runtime Object type and complete for that type.
    if ((0, graphql_1.isAbstractType)(returnType)) {
        return completeAbstractValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord);
    }
    // If field type is Object, execute and complete all sub-selections.
    if ((0, graphql_1.isObjectType)(returnType)) {
        return completeObjectValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord);
    }
    /* c8 ignore next 6 */ // Not reachable, all possible output types have been considered.
    console.assert(false, 'Cannot complete value of unexpected output type: ' + (0, utils_1.inspect)(returnType));
}
/**
 * Returns an object containing the `@stream` arguments if a field should be
 * streamed based on the experimental flag, stream directive present and
 * not disabled by the "if" argument.
 */ function getStreamValues(exeContext, fieldNodes, path) {
    // do not stream inner lists of multi-dimensional lists
    if (typeof path.key === 'number') {
        return;
    }
    // validation only allows equivalent streams on multiple fields, so it is
    // safe to only check the first fieldNode for the stream directive
    const stream = (0, graphql_1.getDirectiveValues)(utils_1.GraphQLStreamDirective, fieldNodes[0], exeContext.variableValues);
    if (!stream) {
        return;
    }
    if (stream.if === false) {
        return;
    }
    (0, invariant_js_1.invariant)(typeof stream['initialCount'] === 'number', 'initialCount must be a number');
    (0, invariant_js_1.invariant)(stream['initialCount'] >= 0, 'initialCount must be a positive integer');
    return {
        initialCount: stream['initialCount'],
        label: typeof stream['label'] === 'string' ? stream['label'] : undefined
    };
}
/**
 * Complete a async iterator value by completing the result and calling
 * recursively until all the results are completed.
 */ async function completeAsyncIteratorValue(exeContext, itemType, fieldNodes, info, path, iterator, asyncPayloadRecord) {
    exeContext.signal?.throwIfAborted();
    if (iterator.return) {
        exeContext.onSignalAbort?.(()=>{
            iterator.return?.();
        });
    }
    const errors = asyncPayloadRecord?.errors ?? exeContext.errors;
    const stream = getStreamValues(exeContext, fieldNodes, path);
    let containsPromise = false;
    const completedResults = [];
    let index = 0;
    while(true){
        if (stream && typeof stream.initialCount === 'number' && index >= stream.initialCount) {
            executeStreamIterator(index, iterator, exeContext, fieldNodes, info, itemType, path, stream.label, asyncPayloadRecord);
            break;
        }
        const itemPath = (0, utils_1.addPath)(path, index, undefined);
        let iteration;
        try {
            iteration = await iterator.next();
            if (iteration.done) {
                break;
            }
        } catch (rawError) {
            const coercedError = (0, coerceError_js_1.coerceError)(rawError);
            const error = (0, utils_1.locatedError)(coercedError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
            completedResults.push(handleFieldError(error, itemType, errors));
            break;
        }
        if (completeListItemValue(iteration.value, completedResults, errors, exeContext, itemType, fieldNodes, info, itemPath, asyncPayloadRecord)) {
            containsPromise = true;
        }
        index += 1;
    }
    return containsPromise ? Promise.all(completedResults) : completedResults;
}
/**
 * Complete a list value by completing each item in the list with the
 * inner type
 */ function completeListValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord) {
    const itemType = returnType.ofType;
    const errors = asyncPayloadRecord?.errors ?? exeContext.errors;
    if ((0, utils_1.isAsyncIterable)(result)) {
        const iterator = result[Symbol.asyncIterator]();
        return completeAsyncIteratorValue(exeContext, itemType, fieldNodes, info, path, iterator, asyncPayloadRecord);
    }
    if (!(0, utils_1.isIterableObject)(result)) {
        throw (0, utils_1.createGraphQLError)(`Expected Iterable, but did not find one for field "${info.parentType.name}.${info.fieldName}".`);
    }
    const stream = getStreamValues(exeContext, fieldNodes, path);
    // This is specified as a simple map, however we're optimizing the path
    // where the list contains no Promises by avoiding creating another Promise.
    let containsPromise = false;
    let previousAsyncPayloadRecord = asyncPayloadRecord;
    const completedResults = [];
    let index = 0;
    for (const item of result){
        // No need to modify the info object containing the path,
        // since from here on it is not ever accessed by resolver functions.
        const itemPath = (0, utils_1.addPath)(path, index, undefined);
        if (stream && typeof stream.initialCount === 'number' && index >= stream.initialCount) {
            previousAsyncPayloadRecord = executeStreamField(path, itemPath, item, exeContext, fieldNodes, info, itemType, stream.label, previousAsyncPayloadRecord);
            index++;
            continue;
        }
        if (completeListItemValue(item, completedResults, errors, exeContext, itemType, fieldNodes, info, itemPath, asyncPayloadRecord)) {
            containsPromise = true;
        }
        index++;
    }
    return containsPromise ? Promise.all(completedResults) : completedResults;
}
/**
 * Complete a list item value by adding it to the completed results.
 *
 * Returns true if the value is a Promise.
 */ function completeListItemValue(item, completedResults, errors, exeContext, itemType, fieldNodes, info, itemPath, asyncPayloadRecord) {
    try {
        let completedItem;
        if ((0, utils_1.isPromise)(item)) {
            completedItem = item.then((resolved)=>completeValue(exeContext, itemType, fieldNodes, info, itemPath, resolved, asyncPayloadRecord));
        } else {
            completedItem = completeValue(exeContext, itemType, fieldNodes, info, itemPath, item, asyncPayloadRecord);
        }
        if ((0, utils_1.isPromise)(completedItem)) {
            // Note: we don't rely on a `catch` method, but we do expect "thenable"
            // to take a second callback for the error case.
            completedResults.push(completedItem.then(undefined, (rawError)=>{
                rawError = (0, coerceError_js_1.coerceError)(rawError);
                const error = (0, utils_1.locatedError)(rawError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
                const handledError = handleFieldError(error, itemType, errors);
                filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
                return handledError;
            }));
            return true;
        }
        completedResults.push(completedItem);
    } catch (rawError) {
        const coercedError = (0, coerceError_js_1.coerceError)(rawError);
        const error = (0, utils_1.locatedError)(coercedError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
        const handledError = handleFieldError(error, itemType, errors);
        filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
        completedResults.push(handledError);
    }
    return false;
}
/**
 * Complete a Scalar or Enum by serializing to a valid value, returning
 * null if serialization is not possible.
 */ function completeLeafValue(returnType, result) {
    let serializedResult;
    // Note: We transform GraphQLError to Error in order to be consistent with
    // how non-null checks work later on.
    // See https://github.com/kamilkisiela/graphql-hive/pull/2299
    // See https://github.com/n1ru4l/envelop/issues/1808
    try {
        serializedResult = returnType.serialize(result);
    } catch (err) {
        if (err instanceof graphql_1.GraphQLError) {
            throw new Error(err.message);
        }
        throw err;
    }
    if (serializedResult == null) {
        throw new Error(`Expected \`${(0, utils_1.inspect)(returnType)}.serialize(${(0, utils_1.inspect)(result)})\` to ` + `return non-nullable value, returned: ${(0, utils_1.inspect)(serializedResult)}`);
    }
    return serializedResult;
}
/**
 * Complete a value of an abstract type by determining the runtime object type
 * of that value, then complete the value for that type.
 */ function completeAbstractValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord) {
    const resolveTypeFn = returnType.resolveType ?? exeContext.typeResolver;
    const contextValue = exeContext.contextValue;
    const runtimeType = resolveTypeFn(result, contextValue, info, returnType);
    if ((0, utils_1.isPromise)(runtimeType)) {
        return runtimeType.then((resolvedRuntimeType)=>completeObjectValue(exeContext, ensureValidRuntimeType(resolvedRuntimeType, exeContext, returnType, fieldNodes, info, result), fieldNodes, info, path, result, asyncPayloadRecord));
    }
    return completeObjectValue(exeContext, ensureValidRuntimeType(runtimeType, exeContext, returnType, fieldNodes, info, result), fieldNodes, info, path, result, asyncPayloadRecord);
}
function ensureValidRuntimeType(runtimeTypeName, exeContext, returnType, fieldNodes, info, result) {
    if (runtimeTypeName == null) {
        throw (0, utils_1.createGraphQLError)(`Abstract type "${returnType.name}" must resolve to an Object type at runtime for field "${info.parentType.name}.${info.fieldName}". Either the "${returnType.name}" type should provide a "resolveType" function or each possible type should provide an "isTypeOf" function.`, {
            nodes: fieldNodes
        });
    }
    // releases before 16.0.0 supported returning `GraphQLObjectType` from `resolveType`
    // TODO: remove in 17.0.0 release
    if ((0, graphql_1.isObjectType)(runtimeTypeName)) {
        if (graphql_1.versionInfo.major >= 16) {
            throw (0, utils_1.createGraphQLError)('Support for returning GraphQLObjectType from resolveType was removed in graphql-js@16.0.0 please return type name instead.');
        }
        runtimeTypeName = runtimeTypeName.name;
    }
    if (typeof runtimeTypeName !== 'string') {
        throw (0, utils_1.createGraphQLError)(`Abstract type "${returnType.name}" must resolve to an Object type at runtime for field "${info.parentType.name}.${info.fieldName}" with ` + `value ${(0, utils_1.inspect)(result)}, received "${(0, utils_1.inspect)(runtimeTypeName)}".`);
    }
    const runtimeType = exeContext.schema.getType(runtimeTypeName);
    if (runtimeType == null) {
        throw (0, utils_1.createGraphQLError)(`Abstract type "${returnType.name}" was resolved to a type "${runtimeTypeName}" that does not exist inside the schema.`, {
            nodes: fieldNodes
        });
    }
    if (!(0, graphql_1.isObjectType)(runtimeType)) {
        throw (0, utils_1.createGraphQLError)(`Abstract type "${returnType.name}" was resolved to a non-object type "${runtimeTypeName}".`, {
            nodes: fieldNodes
        });
    }
    if (!exeContext.schema.isSubType(returnType, runtimeType)) {
        throw (0, utils_1.createGraphQLError)(`Runtime Object type "${runtimeType.name}" is not a possible type for "${returnType.name}".`, {
            nodes: fieldNodes
        });
    }
    return runtimeType;
}
/**
 * Complete an Object value by executing all sub-selections.
 */ function completeObjectValue(exeContext, returnType, fieldNodes, info, path, result, asyncPayloadRecord) {
    // If there is an isTypeOf predicate function, call it with the
    // current result. If isTypeOf returns false, then raise an error rather
    // than continuing execution.
    if (returnType.isTypeOf) {
        const isTypeOf = returnType.isTypeOf(result, exeContext.contextValue, info);
        if ((0, utils_1.isPromise)(isTypeOf)) {
            return isTypeOf.then((resolvedIsTypeOf)=>{
                if (!resolvedIsTypeOf) {
                    throw invalidReturnTypeError(returnType, result, fieldNodes);
                }
                return collectAndExecuteSubfields(exeContext, returnType, fieldNodes, path, result, asyncPayloadRecord);
            });
        }
        if (!isTypeOf) {
            throw invalidReturnTypeError(returnType, result, fieldNodes);
        }
    }
    return collectAndExecuteSubfields(exeContext, returnType, fieldNodes, path, result, asyncPayloadRecord);
}
function invalidReturnTypeError(returnType, result, fieldNodes) {
    return (0, utils_1.createGraphQLError)(`Expected value of type "${returnType.name}" but got: ${(0, utils_1.inspect)(result)}.`, {
        nodes: fieldNodes
    });
}
function collectAndExecuteSubfields(exeContext, returnType, fieldNodes, path, result, asyncPayloadRecord) {
    // Collect sub-fields to execute to complete this value.
    const { fields: subFieldNodes, patches: subPatches } = collectSubfields(exeContext, returnType, fieldNodes);
    const subFields = executeFields(exeContext, returnType, result, path, subFieldNodes, asyncPayloadRecord);
    for (const subPatch of subPatches){
        const { label, fields: subPatchFieldNodes } = subPatch;
        executeDeferredFragment(exeContext, returnType, result, subPatchFieldNodes, label, path, asyncPayloadRecord);
    }
    return subFields;
}
/**
 * If a resolveType function is not given, then a default resolve behavior is
 * used which attempts two strategies:
 *
 * First, See if the provided value has a `__typename` field defined, if so, use
 * that value as name of the resolved type.
 *
 * Otherwise, test each possible type for the abstract type by calling
 * isTypeOf for the object being coerced, returning the first type that matches.
 */ const defaultTypeResolver = function(value, contextValue, info, abstractType) {
    // First, look for `__typename`.
    if ((0, utils_1.isObjectLike)(value) && typeof value['__typename'] === 'string') {
        return value['__typename'];
    }
    // Otherwise, test each possible type.
    const possibleTypes = info.schema.getPossibleTypes(abstractType);
    const promisedIsTypeOfResults = [];
    for(let i = 0; i < possibleTypes.length; i++){
        const type = possibleTypes[i];
        if (type.isTypeOf) {
            const isTypeOfResult = type.isTypeOf(value, contextValue, info);
            if ((0, utils_1.isPromise)(isTypeOfResult)) {
                promisedIsTypeOfResults[i] = isTypeOfResult;
            } else if (isTypeOfResult) {
                return type.name;
            }
        }
    }
    if (promisedIsTypeOfResults.length) {
        return Promise.all(promisedIsTypeOfResults).then((isTypeOfResults)=>{
            for(let i = 0; i < isTypeOfResults.length; i++){
                if (isTypeOfResults[i]) {
                    return possibleTypes[i].name;
                }
            }
        });
    }
};
exports.defaultTypeResolver = defaultTypeResolver;
/**
 * If a resolve function is not given, then a default resolve behavior is used
 * which takes the property of the source object of the same name as the field
 * and returns it as the result, or if it's a function, returns the result
 * of calling that function while passing along args and context value.
 */ const defaultFieldResolver = function(source, args, contextValue, info) {
    // ensure source is a value for which property access is acceptable.
    if ((0, utils_1.isObjectLike)(source) || typeof source === 'function') {
        const property = source[info.fieldName];
        if (typeof property === 'function') {
            return source[info.fieldName](args, contextValue, info);
        }
        return property;
    }
};
exports.defaultFieldResolver = defaultFieldResolver;
/**
 * Implements the "Subscribe" algorithm described in the GraphQL specification,
 * including `@defer` and `@stream` as proposed in
 * https://github.com/graphql/graphql-spec/pull/742
 *
 * Returns a Promise which resolves to either an AsyncIterator (if successful)
 * or an ExecutionResult (error). The promise will be rejected if the schema or
 * other arguments to this function are invalid, or if the resolved event stream
 * is not an async iterable.
 *
 * If the client-provided arguments to this function do not result in a
 * compliant subscription, a GraphQL Response (ExecutionResult) with descriptive
 * errors and no data will be returned.
 *
 * If the source stream could not be created due to faulty subscription resolver
 * logic or underlying systems, the promise will resolve to a single
 * ExecutionResult containing `errors` and no `data`.
 *
 * If the operation succeeded, the promise resolves to an AsyncIterator, which
 * yields a stream of result representing the response stream.
 *
 * Each result may be an ExecutionResult with no `hasNext` (if executing the
 * event did not use `@defer` or `@stream`), or an
 * `InitialIncrementalExecutionResult` or `SubsequentIncrementalExecutionResult`
 * (if executing the event used `@defer` or `@stream`). In the case of
 * incremental execution results, each event produces a single
 * `InitialIncrementalExecutionResult` followed by one or more
 * `SubsequentIncrementalExecutionResult`s; all but the last have `hasNext: true`,
 * and the last has `hasNext: false`. There is no interleaving between results
 * generated from the same original event.
 *
 * Accepts an object with named arguments.
 */ function subscribe(args) {
    // If a valid execution context cannot be created due to incorrect arguments,
    // a "Response" with only errors is returned.
    const exeContext = buildExecutionContext(args);
    // Return early errors if execution context failed.
    if (!('schema' in exeContext)) {
        for (const error of exeContext){
            // @ts-expect-error - We are intentionally modifying the errors
            const extensions = error.extensions ||= {};
            const httpExtensions = extensions['http'] ||= {};
            httpExtensions.status = 400;
            error.extensions['code'] = 'BAD_USER_INPUT';
        }
        return {
            errors: exeContext
        };
    }
    const resultOrStream = createSourceEventStreamImpl(exeContext);
    if ((0, utils_1.isPromise)(resultOrStream)) {
        return resultOrStream.then((resolvedResultOrStream)=>mapSourceToResponse(exeContext, resolvedResultOrStream));
    }
    return mapSourceToResponse(exeContext, resultOrStream);
}
function isIncrementalResults(results) {
    return results?.initialResult;
}
function flattenIncrementalResults(incrementalResults) {
    const subsequentIterator = incrementalResults.subsequentResults;
    let initialResultSent = false;
    let done = false;
    return {
        [Symbol.asyncIterator] () {
            return this;
        },
        next () {
            if (done) {
                return (0, utils_1.fakePromise)({
                    value: undefined,
                    done
                });
            }
            if (initialResultSent) {
                return subsequentIterator.next();
            }
            initialResultSent = true;
            return (0, utils_1.fakePromise)({
                value: incrementalResults.initialResult,
                done
            });
        },
        return () {
            done = true;
            return subsequentIterator.return();
        },
        throw (error) {
            done = true;
            return subsequentIterator.throw(error);
        },
        [disposablestack_1.DisposableSymbols.asyncDispose] () {
            done = true;
            return subsequentIterator?.[disposablestack_1.DisposableSymbols.asyncDispose]?.();
        }
    };
}
async function* ensureAsyncIterable(someExecutionResult) {
    if ('initialResult' in someExecutionResult) {
        yield* flattenIncrementalResults(someExecutionResult);
    } else {
        yield someExecutionResult;
    }
}
function mapSourceToResponse(exeContext, resultOrStream) {
    if (!(0, utils_1.isAsyncIterable)(resultOrStream)) {
        return resultOrStream;
    }
    // For each payload yielded from a subscription, map it over the normal
    // GraphQL `execute` function, with `payload` as the rootValue.
    // This implements the "MapSourceToResponseEvent" algorithm described in
    // the GraphQL specification. The `execute` function provides the
    // "ExecuteSubscriptionEvent" algorithm, as it is nearly identical to the
    // "ExecuteQuery" algorithm, for which `execute` is also used.
    return (0, flattenAsyncIterable_js_1.flattenAsyncIterable)((0, utils_1.mapAsyncIterator)(resultOrStream, (payload)=>(0, promise_helpers_1.handleMaybePromise)(()=>executeImpl(buildPerEventExecutionContext(exeContext, payload)), ensureAsyncIterable), (error)=>{
        if (error instanceof AggregateError) {
            throw new AggregateError(error.errors.map((e)=>wrapError(e, exeContext.operation)), error.message);
        }
        throw wrapError(error, exeContext.operation);
    }));
}
function wrapError(error, operation) {
    return (0, utils_1.createGraphQLError)(error.message, {
        originalError: error,
        nodes: [
            operation
        ]
    });
}
function createSourceEventStreamImpl(exeContext) {
    try {
        const eventStream = executeSubscription(exeContext);
        if ((0, utils_1.isPromise)(eventStream)) {
            return eventStream.then(undefined, (error)=>({
                    errors: [
                        error
                    ]
                }));
        }
        return eventStream;
    } catch (error) {
        return {
            errors: [
                error
            ]
        };
    }
}
function executeSubscription(exeContext) {
    const { schema, fragments, operation, variableValues, rootValue } = exeContext;
    const rootType = schema.getSubscriptionType();
    if (rootType == null) {
        throw (0, utils_1.createGraphQLError)('Schema is not configured to execute subscription operation.', {
            nodes: operation
        });
    }
    const { fields: rootFields } = (0, utils_1.collectFields)(schema, fragments, variableValues, rootType, operation.selectionSet);
    const [responseName, fieldNodes] = [
        ...rootFields.entries()
    ][0];
    const fieldName = fieldNodes[0].name.value;
    const fieldDef = getFieldDef(schema, rootType, fieldNodes[0]);
    if (!fieldDef) {
        throw (0, utils_1.createGraphQLError)(`The subscription field "${fieldName}" is not defined.`, {
            nodes: fieldNodes
        });
    }
    const path = (0, utils_1.addPath)(undefined, responseName, rootType.name);
    const info = buildResolveInfo(exeContext, fieldDef, fieldNodes, rootType, path);
    try {
        // Implements the "ResolveFieldEventStream" algorithm from GraphQL specification.
        // It differs from "ResolveFieldValue" due to providing a different `resolveFn`.
        // Build a JS object of arguments from the field.arguments AST, using the
        // variables scope to fulfill any variable references.
        const args = (0, utils_1.getArgumentValues)(fieldDef, fieldNodes[0], variableValues);
        // The resolve function's optional third argument is a context value that
        // is provided to every resolve function within an execution. It is commonly
        // used to represent an authenticated user, or request-specific caches.
        const contextValue = exeContext.contextValue;
        // Call the `subscribe()` resolver or the default resolver to produce an
        // AsyncIterable yielding raw payloads.
        const resolveFn = fieldDef.subscribe ?? exeContext.subscribeFieldResolver;
        const result = resolveFn(rootValue, args, contextValue, info);
        if ((0, utils_1.isPromise)(result)) {
            return result.then((result)=>assertEventStream(result, exeContext.signal, exeContext.onSignalAbort)).then(undefined, (error)=>{
                throw (0, utils_1.locatedError)(error, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
            });
        }
        return assertEventStream(result, exeContext.signal, exeContext.onSignalAbort);
    } catch (error) {
        throw (0, utils_1.locatedError)(error, fieldNodes, (0, utils_1.pathToArray)(path), exeContext.schemaCoordinateInErrors && info);
    }
}
function assertEventStream(result, signal, onSignalAbort) {
    signal?.throwIfAborted();
    if (result instanceof Error) {
        throw result;
    }
    // Assert field returned an event stream, otherwise yield an error.
    if (!(0, utils_1.isAsyncIterable)(result)) {
        throw (0, utils_1.createGraphQLError)('Subscription field must return Async Iterable. ' + `Received: ${(0, utils_1.inspect)(result)}.`);
    }
    if (onSignalAbort) {
        return {
            [Symbol.asyncIterator] () {
                const asyncIterator = result[Symbol.asyncIterator]();
                if (asyncIterator.return) {
                    onSignalAbort?.(()=>{
                        asyncIterator.return?.();
                    });
                }
                return asyncIterator;
            }
        };
    }
    return result;
}
function executeDeferredFragment(exeContext, parentType, sourceValue, fields, label, path, parentContext) {
    const asyncPayloadRecord = new DeferredFragmentRecord({
        label,
        path,
        parentContext,
        exeContext
    });
    let promiseOrData;
    try {
        promiseOrData = executeFields(exeContext, parentType, sourceValue, path, fields, asyncPayloadRecord);
        if ((0, utils_1.isPromise)(promiseOrData)) {
            promiseOrData = promiseOrData.then(null, (e)=>{
                asyncPayloadRecord.errors.push(e);
                return null;
            });
        }
    } catch (e) {
        asyncPayloadRecord.errors.push(e);
        promiseOrData = null;
    }
    asyncPayloadRecord.addData(promiseOrData);
}
function executeStreamField(path, itemPath, item, exeContext, fieldNodes, info, itemType, label, parentContext) {
    const asyncPayloadRecord = new StreamRecord({
        label,
        path: itemPath,
        parentContext,
        exeContext
    });
    let completedItem;
    try {
        try {
            if ((0, utils_1.isPromise)(item)) {
                completedItem = item.then((resolved)=>completeValue(exeContext, itemType, fieldNodes, info, itemPath, resolved, asyncPayloadRecord));
            } else {
                completedItem = completeValue(exeContext, itemType, fieldNodes, info, itemPath, item, asyncPayloadRecord);
            }
            if ((0, utils_1.isPromise)(completedItem)) {
                // Note: we don't rely on a `catch` method, but we do expect "thenable"
                // to take a second callback for the error case.
                completedItem = completedItem.then(undefined, (rawError)=>{
                    rawError = (0, coerceError_js_1.coerceError)(rawError);
                    const error = (0, utils_1.locatedError)(rawError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
                    const handledError = handleFieldError(error, itemType, asyncPayloadRecord.errors);
                    filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
                    return handledError;
                });
            }
        } catch (rawError) {
            const coercedError = (0, coerceError_js_1.coerceError)(rawError);
            const error = (0, utils_1.locatedError)(coercedError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
            completedItem = handleFieldError(error, itemType, asyncPayloadRecord.errors);
            filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
        }
    } catch (error) {
        asyncPayloadRecord.errors.push(error);
        filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
        asyncPayloadRecord.addItems(null);
        return asyncPayloadRecord;
    }
    let completedItems;
    if ((0, utils_1.isPromise)(completedItem)) {
        completedItems = completedItem.then((value)=>[
                value
            ], (error)=>{
            asyncPayloadRecord.errors.push(error);
            filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
            return null;
        });
    } else {
        completedItems = [
            completedItem
        ];
    }
    asyncPayloadRecord.addItems(completedItems);
    return asyncPayloadRecord;
}
async function executeStreamIteratorItem(iterator, exeContext, fieldNodes, info, itemType, asyncPayloadRecord, itemPath) {
    let item;
    try {
        const { value, done } = await iterator.next();
        if (done) {
            asyncPayloadRecord.setIsCompletedIterator();
            return {
                done,
                value: undefined
            };
        }
        item = value;
    } catch (rawError) {
        const coercedError = (0, coerceError_js_1.coerceError)(rawError);
        const error = (0, utils_1.locatedError)(coercedError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
        const value = handleFieldError(error, itemType, asyncPayloadRecord.errors);
        // don't continue if iterator throws
        return {
            done: true,
            value
        };
    }
    let completedItem;
    try {
        completedItem = completeValue(exeContext, itemType, fieldNodes, info, itemPath, item, asyncPayloadRecord);
        if ((0, utils_1.isPromise)(completedItem)) {
            completedItem = completedItem.then(undefined, (rawError)=>{
                const error = (0, utils_1.locatedError)(rawError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
                const handledError = handleFieldError(error, itemType, asyncPayloadRecord.errors);
                filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
                return handledError;
            });
        }
        return {
            done: false,
            value: completedItem
        };
    } catch (rawError) {
        const error = (0, utils_1.locatedError)(rawError, fieldNodes, (0, utils_1.pathToArray)(itemPath), exeContext.schemaCoordinateInErrors && info);
        const value = handleFieldError(error, itemType, asyncPayloadRecord.errors);
        filterSubsequentPayloads(exeContext, itemPath, asyncPayloadRecord);
        return {
            done: false,
            value
        };
    }
}
async function executeStreamIterator(initialIndex, iterator, exeContext, fieldNodes, info, itemType, path, label, parentContext) {
    let index = initialIndex;
    let previousAsyncPayloadRecord = parentContext ?? undefined;
    while(true){
        const itemPath = (0, utils_1.addPath)(path, index, undefined);
        const asyncPayloadRecord = new StreamRecord({
            label,
            path: itemPath,
            parentContext: previousAsyncPayloadRecord,
            iterator,
            exeContext
        });
        let iteration;
        try {
            iteration = await executeStreamIteratorItem(iterator, exeContext, fieldNodes, info, itemType, asyncPayloadRecord, itemPath);
        } catch (error) {
            asyncPayloadRecord.errors.push(error);
            filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
            asyncPayloadRecord.addItems(null);
            // entire stream has errored and bubbled upwards
            if (iterator?.return) {
                iterator.return().catch(()=>{
                // ignore errors
                });
            }
            return;
        }
        const { done, value: completedItem } = iteration;
        let completedItems;
        if ((0, utils_1.isPromise)(completedItem)) {
            completedItems = completedItem.then((value)=>[
                    value
                ], (error)=>{
                asyncPayloadRecord.errors.push(error);
                filterSubsequentPayloads(exeContext, path, asyncPayloadRecord);
                return null;
            });
        } else {
            completedItems = [
                completedItem
            ];
        }
        asyncPayloadRecord.addItems(completedItems);
        if (done) {
            break;
        }
        previousAsyncPayloadRecord = asyncPayloadRecord;
        index++;
    }
}
function filterSubsequentPayloads(exeContext, nullPath, currentAsyncRecord) {
    const nullPathArray = (0, utils_1.pathToArray)(nullPath);
    exeContext.subsequentPayloads.forEach((asyncRecord)=>{
        if (asyncRecord === currentAsyncRecord) {
            // don't remove payload from where error originates
            return;
        }
        for(let i = 0; i < nullPathArray.length; i++){
            if (asyncRecord.path[i] !== nullPathArray[i]) {
                // asyncRecord points to a path unaffected by this payload
                return;
            }
        }
        // asyncRecord path points to nulled error field
        if (isStreamPayload(asyncRecord) && asyncRecord.iterator?.return) {
            asyncRecord.iterator.return().catch(()=>{
            // ignore error
            });
        }
        exeContext.subsequentPayloads.delete(asyncRecord);
    });
}
function getCompletedIncrementalResults(exeContext) {
    const incrementalResults = [];
    for (const asyncPayloadRecord of exeContext.subsequentPayloads){
        const incrementalResult = {};
        if (!asyncPayloadRecord.isCompleted) {
            continue;
        }
        exeContext.subsequentPayloads.delete(asyncPayloadRecord);
        if (isStreamPayload(asyncPayloadRecord)) {
            const items = asyncPayloadRecord.items;
            if (asyncPayloadRecord.isCompletedIterator) {
                continue;
            }
            incrementalResult.items = items;
        } else {
            const data = asyncPayloadRecord.data;
            incrementalResult.data = data ?? null;
        }
        incrementalResult.path = asyncPayloadRecord.path;
        if (asyncPayloadRecord.label) {
            incrementalResult.label = asyncPayloadRecord.label;
        }
        if (asyncPayloadRecord.errors.length > 0) {
            incrementalResult.errors = asyncPayloadRecord.errors;
        }
        incrementalResults.push(incrementalResult);
    }
    return incrementalResults;
}
function yieldSubsequentPayloads(exeContext) {
    let isDone = false;
    async function next() {
        if (isDone) {
            return {
                value: undefined,
                done: true
            };
        }
        const subSequentPayloadPromises = Array.from(exeContext.subsequentPayloads).map((record)=>record.promise);
        if (exeContext.signalPromise) {
            await Promise.race([
                exeContext.signalPromise,
                ...subSequentPayloadPromises
            ]);
        } else {
            await Promise.race(subSequentPayloadPromises);
        }
        if (isDone) {
            // a different call to next has exhausted all payloads
            return {
                value: undefined,
                done: true
            };
        }
        const incremental = getCompletedIncrementalResults(exeContext);
        const hasNext = exeContext.subsequentPayloads.size > 0;
        if (!incremental.length && hasNext) {
            return next();
        }
        if (!hasNext) {
            isDone = true;
        }
        return {
            value: incremental.length ? {
                incremental,
                hasNext
            } : {
                hasNext
            },
            done: false
        };
    }
    function returnStreamIterators() {
        const promises = [];
        exeContext.subsequentPayloads.forEach((asyncPayloadRecord)=>{
            if (isStreamPayload(asyncPayloadRecord) && asyncPayloadRecord.iterator?.return) {
                promises.push(asyncPayloadRecord.iterator.return());
            }
        });
        return Promise.all(promises);
    }
    return {
        [Symbol.asyncIterator] () {
            return this;
        },
        next,
        async return () {
            await returnStreamIterators();
            isDone = true;
            return {
                value: undefined,
                done: true
            };
        },
        async throw (error) {
            await returnStreamIterators();
            isDone = true;
            throw error;
        },
        async [disposablestack_1.DisposableSymbols.asyncDispose] () {
            await returnStreamIterators();
            isDone = true;
        }
    };
}
class DeferredFragmentRecord {
    type;
    errors;
    label;
    path;
    promise;
    data;
    parentContext;
    isCompleted;
    _exeContext;
    _resolve;
    constructor(opts){
        this.type = 'defer';
        this.label = opts.label;
        this.path = (0, utils_1.pathToArray)(opts.path);
        this.parentContext = opts.parentContext;
        this.errors = [];
        this._exeContext = opts.exeContext;
        this._exeContext.subsequentPayloads.add(this);
        this.isCompleted = false;
        this.data = null;
        this.promise = new Promise((resolve)=>{
            this._resolve = (MaybePromise)=>{
                resolve(MaybePromise);
            };
        }).then((data)=>{
            this.data = data;
            this.isCompleted = true;
        });
    }
    addData(data) {
        const parentData = this.parentContext?.promise;
        if (parentData) {
            this._resolve?.(parentData.then(()=>data));
            return;
        }
        this._resolve?.(data);
    }
}
class StreamRecord {
    type;
    errors;
    label;
    path;
    items;
    promise;
    parentContext;
    iterator;
    isCompletedIterator;
    isCompleted;
    _exeContext;
    _resolve;
    constructor(opts){
        this.type = 'stream';
        this.items = null;
        this.label = opts.label;
        this.path = (0, utils_1.pathToArray)(opts.path);
        this.parentContext = opts.parentContext;
        this.iterator = opts.iterator;
        this.errors = [];
        this._exeContext = opts.exeContext;
        this._exeContext.subsequentPayloads.add(this);
        this.isCompleted = false;
        this.items = null;
        this.promise = new Promise((resolve)=>{
            this._resolve = (MaybePromise)=>{
                resolve(MaybePromise);
            };
        }).then((items)=>{
            this.items = items;
            this.isCompleted = true;
        });
    }
    addItems(items) {
        const parentData = this.parentContext?.promise;
        if (parentData) {
            this._resolve?.(parentData.then(()=>items));
            return;
        }
        this._resolve?.(items);
    }
    setIsCompletedIterator() {
        this.isCompletedIterator = true;
    }
}
function isStreamPayload(asyncPayload) {
    return asyncPayload.type === 'stream';
}
/**
 * This method looks up the field on the given type definition.
 * It has special casing for the three introspection fields,
 * __schema, __type and __typename. __typename is special because
 * it can always be queried as a field, even in situations where no
 * other fields are allowed, like on a Union. __schema and __type
 * could get automatically added to the query type, but that would
 * require mutating type definitions, which would cause issues.
 *
 * @internal
 */ function getFieldDef(schema, parentType, fieldNode) {
    const fieldName = fieldNode.name.value;
    if (fieldName === graphql_1.SchemaMetaFieldDef.name && schema.getQueryType() === parentType) {
        return graphql_1.SchemaMetaFieldDef;
    } else if (fieldName === graphql_1.TypeMetaFieldDef.name && schema.getQueryType() === parentType) {
        return graphql_1.TypeMetaFieldDef;
    } else if (fieldName === graphql_1.TypeNameMetaFieldDef.name) {
        return graphql_1.TypeNameMetaFieldDef;
    }
    return parentType.getFields()[fieldName];
}
function isIncrementalResult(result) {
    return 'incremental' in result;
}
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/normalizedExecutor.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.executorFromSchema = void 0;
exports.normalizedExecutor = normalizedExecutor;
const graphql_1 = __turbopack_context__.r("[project]/node_modules/graphql/index.mjs [app-route] (ecmascript)");
const utils_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/utils/cjs/index.js [app-route] (ecmascript)");
const promise_helpers_1 = __turbopack_context__.r("[project]/node_modules/@whatwg-node/promise-helpers/cjs/index.js [app-route] (ecmascript)");
const execute_js_1 = __turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/execute.js [app-route] (ecmascript)");
function normalizedExecutor(args) {
    const operationAST = (0, graphql_1.getOperationAST)(args.document, args.operationName);
    if (operationAST == null) {
        throw new Error('Must provide an operation.');
    }
    if (operationAST.operation === 'subscription') {
        return (0, execute_js_1.subscribe)(args);
    }
    return (0, promise_helpers_1.handleMaybePromise)(()=>(0, execute_js_1.execute)(args), (result)=>{
        if ((0, execute_js_1.isIncrementalResults)(result)) {
            return (0, execute_js_1.flattenIncrementalResults)(result);
        }
        return result;
    });
}
exports.executorFromSchema = (0, utils_1.memoize1)(function executorFromSchema(schema) {
    return function schemaExecutor(request) {
        return normalizedExecutor({
            schema,
            document: request.document,
            variableValues: request.variables,
            operationName: request.operationName,
            rootValue: request.rootValue,
            contextValue: request.context,
            signal: request.signal || request.info?.signal,
            schemaCoordinateInErrors: request.schemaCoordinateInErrors
        });
    };
});
}),
"[project]/node_modules/@graphql-tools/executor/cjs/execution/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
const tslib_1 = __turbopack_context__.r("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/execute.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/values.js [app-route] (ecmascript)"), exports);
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/normalizedExecutor.js [app-route] (ecmascript)"), exports);
}),
"[project]/node_modules/@graphql-tools/executor/cjs/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
const tslib_1 = __turbopack_context__.r("[project]/node_modules/tslib/tslib.es6.mjs [app-route] (ecmascript)");
tslib_1.__exportStar(__turbopack_context__.r("[project]/node_modules/@graphql-tools/executor/cjs/execution/index.js [app-route] (ecmascript)"), exports);
}),
];

//# sourceMappingURL=node_modules_%40graphql-tools_b5b2d37b._.js.map